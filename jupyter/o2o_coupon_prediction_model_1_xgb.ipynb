{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_alpha = pd.read_csv('../features/dataset_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beta = pd.read_csv('../features/dataset_beta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [\n",
    "    'Distance',\n",
    "    'Month_of_received', 'Day_of_received',\n",
    "       'Weekday_of_received', 'Base_consume', 'Discount',\n",
    "       'Discount_money', 'Coupon_type', 'Coupon_category',\n",
    "    'Previous_duration', 'Next_duration', 'o1',\n",
    "       'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
    "       'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
    "       'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
    "       'o30', 'o38', 'o31', 'o39', 'o32', 'o33', 'o34', 'o35', 'o36',\n",
    "       'o37', 'u1', 'u2', 'u3', 'u4', 'u5', 'u6',\n",
    "       'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13', 'u14', 'u15', 'u16',\n",
    "       'u17', 'u18', 'u19', 'u20', 'u21', 'u22', 'u23', 'u24', 'u25',\n",
    "       'ucc1', 'ucc2', 'ucc3', 'ucc4', 'ucc5', 'ucc6', 'ucc7', 'ucc8',\n",
    "       'ucc9', 'ucc10', 'ucc11', 'ucc12', 'uc1', 'uc2', 'uc3', 'uc4',\n",
    "       'uc5', 'uc6', 'uc7', 'uc8', 'uc9', 'uc10', 'uc11', 'uc12', 'ud1',\n",
    "       'ud2', 'ud3', 'ud4', 'ud5', 'ud6', 'ud7', 'ud8', 'ud9', 'ud10',\n",
    "       'ud11', 'ud12', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8',\n",
    "       'm9', 'm10', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9',\n",
    "       'c10', 'ou1', 'ou2', 'ou3', 'ou4']\n",
    "\n",
    "label = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeFeature(TransformerMixin):\n",
    "    def __init__(self, df, key, prefix, pipe):\n",
    "        self.df = df\n",
    "        self.key = key\n",
    "        self.prefix = prefix\n",
    "        self.pipe = pipe\n",
    "    \n",
    "    def get_factor(self, df, key, prefix):\n",
    "        id_df = df[[key]]\n",
    "        output_df = df.drop([key], axis=1)\n",
    "\n",
    "        self.pipe.fit(output_df)\n",
    "        factors = self.pipe.transform(output_df)\n",
    "        factors_df = pd.DataFrame(data=factors, columns=[prefix + '_factor_alpha', prefix + '_factor_beta'])\n",
    "        factors_df[key] = id_df[key]\n",
    "        return factors_df\n",
    "    \n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.merge(X, self.df, on=self.key, how='left')\n",
    "#         return pd.merge(X, self.get_factor(self.df, self.key, self.prefix), on=[self.key], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('scale', MinMaxScaler()),\n",
    "])\n",
    "\n",
    "features_pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "#             ('scale', MinMaxScaler()),\n",
    "            ('normalize', Normalizer())\n",
    "        ])),\n",
    "#         ('fields', Pipeline([\n",
    "#             ('extract', ColumnSelector(fields)),\n",
    "#             ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "#             ('one_hot', OneHotEncoder(categories='auto')),\n",
    "#             ('to_dense', DenseTransformer())\n",
    "#         ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "features_pipeline.fit(dataset_beta, dataset_beta.Label.values.ravel())\n",
    "\n",
    "train_dataset_x = features_pipeline.transform(dataset_beta)\n",
    "train_dataset_y = dataset_beta.Label.values.ravel()\n",
    "\n",
    "valid_dataset_x = features_pipeline.transform(dataset_alpha)\n",
    "valid_dataset_y = dataset_alpha.Label.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.7,\n",
       "       colsample_bytree=0.7, eval_metric='auc', gamma=0.1, learn_rate=0.01,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=1.1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.7))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'xgb__learn_rate': [0.001], 'xgb__max_depth': [6], 'xgb__min_child_weight': [1], 'xgb__subsample': [0.7], 'xgb__colsample_bytree': [0.7], 'xgb__colsample_bylevel': [0.7], 'xgb__objective': ['rank:pairwise'], 'xgb__n_estimators': range(100, 401, 100), 'xgb__gamma': [0.1], 'xgb__reg_alpha': [1], 'xgb__reg_lambda': [1], 'xgb__max_delta_step': [0], 'xgb__scale_pos_weight': [1], 'xgb__silent': [True], 'xgb__eval_metric': ['auc']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'xgb__learn_rate': [0.001, ],\n",
    "    'xgb__max_depth': [6],\n",
    "    'xgb__min_child_weight': [1],\n",
    "    'xgb__subsample': [0.7,],\n",
    "    'xgb__colsample_bytree': [0.7,],\n",
    "    'xgb__colsample_bylevel': [0.7,],\n",
    "    'xgb__objective': ['rank:pairwise'],\n",
    "    'xgb__n_estimators': range(100, 401, 100), # 使用1-3都可以被接受\n",
    "    'xgb__gamma': [0.1,],\n",
    "    'xgb__reg_alpha': [1,],\n",
    "    'xgb__reg_lambda': [1,],\n",
    "    'xgb__max_delta_step': [0,],\n",
    "    'xgb__scale_pos_weight': [1,],\n",
    "    'xgb__silent': [True],\n",
    "    'xgb__eval_metric': ['auc']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(model_pipeline, parameters, scoring = 'roc_auc', n_jobs= 4)\n",
    "cv.fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8917712 , 0.90391788, 0.91151292, 0.91780179])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看每组评估的具体数据\n",
    "cv.cv_results_['param_xgb__n_estimators'].data\n",
    "\n",
    "# 结果训练\n",
    "cv.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最优参数训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.7,\n",
       "       colsample_bytree=0.7, eval_metric='auc', gamma=0.1, learn_rate=0.01,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=1.1, missing=None, n_estimators=30, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.7))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('xgb', xgb.sklearn.XGBClassifier())\n",
    "])\n",
    "\n",
    "model_pipeline.set_params(\n",
    "    xgb__learn_rate=0.01,\n",
    "    xgb__max_depth=12,\n",
    "    xgb__min_child_weight=1.1,\n",
    "    xgb__subsample=0.7,\n",
    "    xgb__colsample_bytree=0.7,\n",
    "    xgb__colsample_bylevel=0.7,\n",
    "#     xgb__objective='rank:pairwise',\n",
    "    xgb__objective='binary:logistic',\n",
    "    xgb__n_estimators=30,\n",
    "    xgb__gamma=0.1,\n",
    "    xgb__reg_alpha=1,\n",
    "    xgb__reg_lambda=1,\n",
    "    xgb__max_delta_step=0,\n",
    "    xgb__scale_pos_weight=1,\n",
    "    xgb__silent=True,\n",
    "    xgb__eval_metric='auc'\n",
    ").fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, df, pipe):\n",
    "        self.df = df\n",
    "        self.pipe = pipe\n",
    "        \n",
    "    def transfer_result(self, result):\n",
    "        return MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(result.reshape(-1, 1))\n",
    "    \n",
    "    def cal(self, dataset):\n",
    "        pred = self.pipe.predict_proba(dataset)[:,1]\n",
    "        logging.info(pred)\n",
    "        \n",
    "        self.df['Probability'] = self.transfer_result(pred)\n",
    "        return self.evaluate(self.df[['Probability', 'Coupon_id', 'Label']])\n",
    "    \n",
    "    def describe(self):\n",
    "        return self.df[['User_id', 'Coupon_id', 'Probability', 'Label']].describe()\n",
    "    \n",
    "    def predict(self, dataset):\n",
    "        pred = self.pipe.predict_proba(dataset)[:,1]\n",
    "        logging.info(pred)\n",
    "        \n",
    "        self.df['Probability'] = self.transfer_result(pred)\n",
    "        return self.df[['User_id', 'Coupon_id', 'Date_received', 'Probability']]\n",
    "    \n",
    "    def evaluate(self, result_df):\n",
    "        group = result_df.groupby(['Coupon_id'])\n",
    "        aucs = []\n",
    "        logging.info('coupon size is %d' % (len(group)))\n",
    "\n",
    "        counter = 0\n",
    "        for i in group:\n",
    "            tmpdf = i[1]        \n",
    "            if len(tmpdf['Label'].unique()) != 2:\n",
    "                continue\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(tmpdf['Label'], tmpdf['Probability'], pos_label=1)\n",
    "            auc_score = auc(fpr,tpr)\n",
    "            aucs.append(auc_score)\n",
    "            counter = counter + 1\n",
    "\n",
    "        logging.info('coupon in cal is %d' % (counter))\n",
    "\n",
    "        return np.average(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 01:06:14,827  <ipython-input-11-88d5387b257b> : INFO  [0.03550993 0.36370125 0.16911688 ... 0.08443704 0.02785196 0.05655894]\n",
      "2019-02-06 01:06:15,033  <ipython-input-11-88d5387b257b> : INFO  coupon size is 4800\n",
      "2019-02-06 01:06:17,544  <ipython-input-11-88d5387b257b> : INFO  coupon in cal is 2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7002481518223771"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(dataset_alpha, model_pipeline)\n",
    "evaluator.cal(valid_dataset_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "2019-02-02 12:42:23,332  <ipython-input-12-3fa321e3310d> : INFO  [0.04794511 0.02325486 0.0034588  ... 0.00014111 0.03200784 0.04099259]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(113640, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_df = pd.read_csv('../features/lcm_submit_features.csv')\n",
    "\n",
    "predict_dataset_x = features_pipeline.transform(model_pred_df)\n",
    "predictor = Evaluator(model_pred_df, model_pipeline)\n",
    "final_result_df = predictor.predict(predict_dataset_x)\n",
    "final_result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.136400e+05</td>\n",
       "      <td>113640.000000</td>\n",
       "      <td>1.136400e+05</td>\n",
       "      <td>113640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.684858e+06</td>\n",
       "      <td>9053.810929</td>\n",
       "      <td>2.016072e+07</td>\n",
       "      <td>0.045039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.126259e+06</td>\n",
       "      <td>4145.873088</td>\n",
       "      <td>9.019508e+00</td>\n",
       "      <td>0.083413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.090000e+02</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.016070e+07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.844191e+06</td>\n",
       "      <td>5023.000000</td>\n",
       "      <td>2.016071e+07</td>\n",
       "      <td>0.017546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.683266e+06</td>\n",
       "      <td>9983.000000</td>\n",
       "      <td>2.016072e+07</td>\n",
       "      <td>0.027178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.525845e+06</td>\n",
       "      <td>13602.000000</td>\n",
       "      <td>2.016072e+07</td>\n",
       "      <td>0.043449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.361024e+06</td>\n",
       "      <td>14045.000000</td>\n",
       "      <td>2.016073e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User_id      Coupon_id  Date_received    Probability\n",
       "count  1.136400e+05  113640.000000   1.136400e+05  113640.000000\n",
       "mean   3.684858e+06    9053.810929   2.016072e+07       0.045039\n",
       "std    2.126259e+06    4145.873088   9.019508e+00       0.083413\n",
       "min    2.090000e+02       3.000000   2.016070e+07       0.000000\n",
       "25%    1.844191e+06    5023.000000   2.016071e+07       0.017546\n",
       "50%    3.683266e+06    9983.000000   2.016072e+07       0.027178\n",
       "75%    5.525845e+06   13602.000000   2.016072e+07       0.043449\n",
       "max    7.361024e+06   14045.000000   2.016073e+07       1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_df.to_csv('/Users/leewind/Desktop/submission_20190201_1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
