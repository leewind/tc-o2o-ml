{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_PRED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_alpha = pd.read_csv('../features/dataset_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beta = pd.read_csv('../features/dataset_beta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pred = pd.read_csv('../features/dataset_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PRED:\n",
    "    dataset_beta = pd.concat([dataset_alpha, dataset_beta])\n",
    "    dataset_alpha = dataset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [\n",
    "    'Coupon_id', 'Distance',\n",
    "    'Month_of_received', 'Day_of_received',\n",
    "    'Weekday_of_received', 'Base_consume', 'Discount',\n",
    "    'Discount_money', 'Coupon_type', 'Coupon_category',\n",
    "    'Previous_duration', 'Next_duration', 'o1',\n",
    "    'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
    "    'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
    "    'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
    "    'o30', 'o38', 'o31', 'o39', 'o40', 'o41', 'o42', 'o43', 'o32',\n",
    "    'o33', 'o34', 'o35', 'o36', 'o37', 'o44', 'u0', 'u1', 'u2', 'u3',\n",
    "    'u4', 'u5', 'u6', 'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13',\n",
    "    'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u21', 'u22',\n",
    "    'u23', 'u24', 'u25', 'ucc0', 'ucc1', 'ucc2', 'ucc3', 'ucc4',\n",
    "    'ucc5', 'ucc6', 'ucc7', 'ucc8', 'ucc9', 'ucc10', 'ucc11', 'ucc12',\n",
    "    'uc1', 'uc2', 'uc3', 'uc4', 'uc5', 'uc6', 'uc7', 'uc8', 'uc9',\n",
    "    'uc10', 'uc11', 'uc12', 'ud0', 'ud1', 'ud2', 'ud3', 'ud4', 'ud5',\n",
    "    'ud6', 'ud7', 'ud8', 'ud9', 'ud10', 'ud11', 'ud12', 'um0', 'um1',\n",
    "    'um2', 'um3', 'um4', 'um5', 'um6', 'um7', 'um8', 'um9', 'um10',\n",
    "    'um16', 'um15', 'um17', 'um11', 'um12', 'um13', 'um14', 'm0', 'm1',\n",
    "    'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11',\n",
    "    'm12', 'm13', 'm14', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7',\n",
    "    'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'cd1', 'cd2', 'cd3',\n",
    "    'cd4', 'cd5', 'cd6', 'cd7', 'dr1', 'dr2', 'dr3', 'dr4', 'dr5',\n",
    "    'dr6', 'dr7', 'ou1', 'ou2', 'ou3', 'ou4']\n",
    "\n",
    "label = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "            ('normalize', Normalizer())\n",
    "        ])),\n",
    "#         ('fields', Pipeline([\n",
    "#             ('extract', ColumnSelector(fields)),\n",
    "#             ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "#             ('one_hot', OneHotEncoder(categories='auto')),\n",
    "#             ('to_dense', DenseTransformer())\n",
    "#         ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "features_pipeline.fit(dataset_beta, dataset_beta.Label.values.ravel())\n",
    "\n",
    "train_dataset_x = features_pipeline.transform(dataset_beta)\n",
    "train_dataset_y = dataset_beta.Label.values.ravel()\n",
    "\n",
    "valid_dataset_x = features_pipeline.transform(dataset_alpha)\n",
    "\n",
    "if not IS_PRED:\n",
    "    valid_dataset_y = dataset_alpha.Label.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_model = xgb.sklearn.XGBClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "selector_model.fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.001\n",
    "selection = SelectFromModel(selector_model, threshold=thresh, prefit=True)\n",
    "\n",
    "train_dataset_x = selection.transform(train_dataset_x)\n",
    "valid_dataset_x = selection.transform(valid_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4972972972972973"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_x.shape[1] / len(continous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'xgb__learn_rate': [0.01, ],\n",
    "    'xgb__max_depth': [6],\n",
    "    'xgb__min_child_weight': [1],\n",
    "    'xgb__subsample': [0.7,],\n",
    "    'xgb__colsample_bytree': [0.7,],\n",
    "    'xgb__colsample_bylevel': [0.7,],\n",
    "    'xgb__objective': ['rank:pairwise'],\n",
    "    'xgb__n_estimators': range(100, 401, 100), # 使用1-3都可以被接受\n",
    "    'xgb__gamma': [0.1,],\n",
    "    'xgb__reg_alpha': [1,],\n",
    "    'xgb__reg_lambda': [1,],\n",
    "    'xgb__max_delta_step': [0,],\n",
    "    'xgb__scale_pos_weight': [1,],\n",
    "    'xgb__silent': [True],\n",
    "    'xgb__eval_metric': ['auc']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(model_pipeline, parameters, scoring = 'roc_auc', n_jobs= 4)\n",
    "cv.fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每组评估的具体数据\n",
    "cv.cv_results_['param_xgb__n_estimators'].data\n",
    "\n",
    "# 结果训练\n",
    "cv.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最优参数训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.7,\n",
       "       colsample_bytree=0.7, eval_metric='auc', gamma=0, learn_rate=0.01,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
       "       min_child_weight=1.1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=10, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.7))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('xgb', xgb.sklearn.XGBClassifier())\n",
    "])\n",
    "\n",
    "model_pipeline.set_params(\n",
    "    xgb__learn_rate=0.01,\n",
    "    xgb__max_depth=12,\n",
    "    xgb__min_child_weight=1.1,\n",
    "    xgb__subsample=0.7,\n",
    "    xgb__colsample_bytree=0.7,\n",
    "    xgb__colsample_bylevel=0.7,\n",
    "#     xgb__objective='rank:pairwise',\n",
    "    xgb__objective='binary:logistic',\n",
    "    xgb__n_estimators=200,\n",
    "#     xgb__gamma=0.1,\n",
    "#     xgb__reg_alpha=1,\n",
    "    xgb__reg_lambda=10,\n",
    "#     xgb__max_delta_step=0,\n",
    "#     xgb__scale_pos_weight=1,\n",
    "    xgb__silent=True,\n",
    "    xgb__eval_metric='auc'\n",
    ").fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, df, pipe):\n",
    "        self.df = df\n",
    "        self.pipe = pipe\n",
    "        \n",
    "    def transfer_result(self, result):\n",
    "        return MinMaxScaler(copy=True, feature_range=(0, 1)).fit_transform(result.reshape(-1, 1))\n",
    "    \n",
    "    def cal(self, dataset):\n",
    "        pred = self.pipe.predict_proba(dataset)[:,1]\n",
    "        logging.info(pred)\n",
    "        \n",
    "        self.df['Probability'] = self.transfer_result(pred)\n",
    "        return self.evaluate(self.df[['Probability', 'Coupon_id', 'Label']])\n",
    "    \n",
    "    def describe(self):\n",
    "        return self.df[['User_id', 'Coupon_id', 'Probability', 'Label']].describe()\n",
    "    \n",
    "    def predict(self, dataset):\n",
    "        pred = self.pipe.predict_proba(dataset)[:,1]\n",
    "        logging.info(pred)\n",
    "        \n",
    "        self.df['Probability'] = self.transfer_result(pred)\n",
    "        return self.df[['User_id', 'Coupon_id', 'Date_received', 'Probability']]\n",
    "    \n",
    "    def evaluate(self, result_df):\n",
    "        group = result_df.groupby(['Coupon_id'])\n",
    "        aucs = []\n",
    "        logging.info('coupon size is %d' % (len(group)))\n",
    "\n",
    "        counter = 0\n",
    "        for i in group:\n",
    "            tmpdf = i[1]        \n",
    "            if len(tmpdf['Label'].unique()) != 2:\n",
    "                continue\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(tmpdf['Label'], tmpdf['Probability'], pos_label=1)\n",
    "            auc_score = auc(fpr,tpr)\n",
    "            aucs.append(auc_score)\n",
    "            counter = counter + 1\n",
    "\n",
    "        logging.info('coupon in cal is %d' % (counter))\n",
    "\n",
    "        return np.average(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 17:11:55,393  <ipython-input-31-88d5387b257b> : INFO  [0.02572334 0.01788806 0.0523413  ... 0.14622833 0.00774132 0.04822461]\n",
      "2019-02-08 17:11:55,631  <ipython-input-31-88d5387b257b> : INFO  coupon size is 4800\n",
      "2019-02-08 17:11:58,391  <ipython-input-31-88d5387b257b> : INFO  coupon in cal is 2048\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(dataset_alpha, model_pipeline)\n",
    "\n",
    "if IS_PRED:\n",
    "    final_result_df = evaluator.predict(valid_dataset_x)\n",
    "    final_result_df.to_csv('/Users/leewind/Desktop/submission_20190208.csv', index=False, header=False)\n",
    "    final_result_df.describe()\n",
    "else:\n",
    "    logger.info(evaluator.cal(valid_dataset_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 17:28:07,298  <ipython-input-36-88d5387b257b> : INFO  [0.02719907 0.02647771 0.06181328 ... 0.13776243 0.01090022 0.0495923 ]\n",
      "2019-02-08 17:28:07,514  <ipython-input-36-88d5387b257b> : INFO  coupon size is 4800\n",
      "2019-02-08 17:28:10,827  <ipython-input-36-88d5387b257b> : INFO  coupon in cal is 2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7099751430695382"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = Evaluator(dataset_beta, model_pipeline)\n",
    "evaluator.cal(train_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
