{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_PRED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_alpha = pd.read_csv('../features/dataset_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beta = pd.read_csv('../features/dataset_beta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pred = pd.read_csv('../features/dataset_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_PRED:\n",
    "    dataset_beta = pd.concat([dataset_alpha, dataset_beta])\n",
    "    dataset_alpha = dataset_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [\n",
    "    'Coupon_id', 'Distance',\n",
    "    'Month_of_received', 'Day_of_received',\n",
    "    'Weekday_of_received', 'Base_consume', 'Discount',\n",
    "    'Discount_money', 'Coupon_type', 'Coupon_category',\n",
    "    'Previous_duration', 'Next_duration', 'o1',\n",
    "    'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
    "    'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
    "    'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
    "    'o30', 'o38', 'o31', 'o39', 'o40', 'o41', 'o42', 'o43', 'o32',\n",
    "    'o33', 'o34', 'o35', 'o36', 'o37', 'o44', 'u0', 'u1', 'u2', 'u3',\n",
    "    'u4', 'u5', 'u6', 'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13',\n",
    "    'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u21', 'u22',\n",
    "    'u23', 'u24', 'u25', 'ucc0', 'ucc1', 'ucc2', 'ucc3', 'ucc4',\n",
    "    'ucc5', 'ucc6', 'ucc7', 'ucc8', 'ucc9', 'ucc10', 'ucc11', 'ucc12',\n",
    "    'uc1', 'uc2', 'uc3', 'uc4', 'uc5', 'uc6', 'uc7', 'uc8', 'uc9',\n",
    "    'uc10', 'uc11', 'uc12', 'ud0', 'ud1', 'ud2', 'ud3', 'ud4', 'ud5',\n",
    "    'ud6', 'ud7', 'ud8', 'ud9', 'ud10', 'ud11', 'ud12', 'um0', 'um1',\n",
    "    'um2', 'um3', 'um4', 'um5', 'um6', 'um7', 'um8', 'um9', 'um10',\n",
    "    'um16', 'um15', 'um17', 'um11', 'um12', 'um13', 'um14', 'm0', 'm1',\n",
    "    'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11',\n",
    "    'm12', 'm13', 'm14', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7',\n",
    "    'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'cd1', 'cd2', 'cd3',\n",
    "    'cd4', 'cd5', 'cd6', 'cd7', 'dr1', 'dr2', 'dr3', 'dr4', 'dr5',\n",
    "    'dr6', 'dr7', 'ou1', 'ou2', 'ou3', 'ou4']\n",
    "\n",
    "label = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "            ('normalize', Normalizer())\n",
    "        ])),\n",
    "#         ('fields', Pipeline([\n",
    "#             ('extract', ColumnSelector(fields)),\n",
    "#             ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "#             ('one_hot', OneHotEncoder(categories='auto')),\n",
    "#             ('to_dense', DenseTransformer())\n",
    "#         ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "features_pipeline.fit(dataset_beta, dataset_beta.Label.values.ravel())\n",
    "\n",
    "train_dataset_x = features_pipeline.transform(dataset_beta)\n",
    "train_dataset_y = dataset_beta.Label.values.ravel()\n",
    "\n",
    "valid_dataset_x = features_pipeline.transform(dataset_alpha)\n",
    "\n",
    "if not IS_PRED:\n",
    "    valid_dataset_y = dataset_alpha.Label.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_model = xgb.sklearn.XGBClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "selector_model.fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.001\n",
    "selection = SelectFromModel(selector_model, threshold=thresh, prefit=True)\n",
    "\n",
    "train_dataset_x = selection.transform(train_dataset_x)\n",
    "valid_dataset_x = selection.transform(valid_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Coupon_id', 0.0071530757),\n",
       " ('Distance', 0.037195995),\n",
       " ('Day_of_received', 0.010014306),\n",
       " ('Weekday_of_received', 0.0028612304),\n",
       " ('Base_consume', 0.03862661),\n",
       " ('Discount', 0.0014306152),\n",
       " ('Discount_money', 0.012875536),\n",
       " ('Coupon_type', 0.0042918455),\n",
       " ('Coupon_category', 0.010014306),\n",
       " ('Previous_duration', 0.0042918455),\n",
       " ('Next_duration', 0.055793993),\n",
       " ('o1', 0.0014306152),\n",
       " ('o3', 0.011444922),\n",
       " ('o4', 0.0028612304),\n",
       " ('o5', 0.0014306152),\n",
       " ('o6', 0.040057223),\n",
       " ('o8', 0.014306151),\n",
       " ('o9', 0.011444922),\n",
       " ('o10', 0.0028612304),\n",
       " ('o14', 0.020028612),\n",
       " ('o11', 0.04434907),\n",
       " ('o13', 0.008583691),\n",
       " ('o16', 0.005722461),\n",
       " ('o15', 0.07439199),\n",
       " ('o18', 0.030042918),\n",
       " ('o21', 0.0028612304),\n",
       " ('o22', 0.005722461),\n",
       " ('o23', 0.0042918455),\n",
       " ('o17', 0.0014306152),\n",
       " ('o24', 0.0014306152),\n",
       " ('o25', 0.0028612304),\n",
       " ('o26', 0.055793993),\n",
       " ('o27', 0.0028612304),\n",
       " ('o28', 0.0042918455),\n",
       " ('o29', 0.0071530757),\n",
       " ('o30', 0.012875536),\n",
       " ('o38', 0.005722461),\n",
       " ('o31', 0.0014306152),\n",
       " ('o39', 0.005722461),\n",
       " ('o40', 0.0014306152),\n",
       " ('o41', 0.0014306152),\n",
       " ('o32', 0.027181689),\n",
       " ('o33', 0.04434907),\n",
       " ('o34', 0.030042918),\n",
       " ('o35', 0.04148784),\n",
       " ('o36', 0.0014306152),\n",
       " ('o37', 0.010014306),\n",
       " ('u0', 0.0028612304),\n",
       " ('u3', 0.0014306152),\n",
       " ('u6', 0.0014306152),\n",
       " ('u7', 0.0014306152),\n",
       " ('u8', 0.0014306152),\n",
       " ('u10', 0.0042918455),\n",
       " ('u12', 0.0028612304),\n",
       " ('u22', 0.0028612304),\n",
       " ('ucc5', 0.0014306152),\n",
       " ('ucc6', 0.0028612304),\n",
       " ('ucc7', 0.010014306),\n",
       " ('uc4', 0.0028612304),\n",
       " ('uc9', 0.010014306),\n",
       " ('uc12', 0.0042918455),\n",
       " ('ud8', 0.011444922),\n",
       " ('ud11', 0.0028612304),\n",
       " ('um2', 0.017167382),\n",
       " ('um3', 0.0014306152),\n",
       " ('um4', 0.0028612304),\n",
       " ('um7', 0.0014306152),\n",
       " ('um8', 0.0014306152),\n",
       " ('um9', 0.0014306152),\n",
       " ('um15', 0.010014306),\n",
       " ('um17', 0.005722461),\n",
       " ('um12', 0.018597998),\n",
       " ('um13', 0.0028612304),\n",
       " ('m0', 0.015736766),\n",
       " ('m1', 0.005722461),\n",
       " ('m2', 0.005722461),\n",
       " ('m4', 0.008583691),\n",
       " ('m5', 0.0042918455),\n",
       " ('m7', 0.0014306152),\n",
       " ('m8', 0.011444922),\n",
       " ('m10', 0.0014306152),\n",
       " ('m11', 0.0028612304),\n",
       " ('m14', 0.012875536),\n",
       " ('c1', 0.005722461),\n",
       " ('c3', 0.0028612304),\n",
       " ('c4', 0.005722461),\n",
       " ('c5', 0.0028612304),\n",
       " ('c7', 0.0042918455),\n",
       " ('c9', 0.028612303),\n",
       " ('c10', 0.015736766),\n",
       " ('c12', 0.010014306),\n",
       " ('cd1', 0.0014306152)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector = []\n",
    "for index, value in enumerate(selector_model.feature_importances_):\n",
    "    if value > 0:\n",
    "        feature_selector.append((continous[index], value))\n",
    "\n",
    "feature_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4972972972972973"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_x.shape[1] / len(continous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252586, 92)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-09 16:42:24,467  <ipython-input-27-2557adcfd4fe> : INFO  3-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820 +/- 0.00 {'kneighborsclassifier__n_neighbors': 1, 'meta-logisticregression__C': 0.1, 'randomforestclassifier__n_estimators': 10}\n",
      "0.868 +/- 0.00 {'kneighborsclassifier__n_neighbors': 1, 'meta-logisticregression__C': 0.1, 'randomforestclassifier__n_estimators': 200}\n",
      "0.820 +/- 0.00 {'kneighborsclassifier__n_neighbors': 1, 'meta-logisticregression__C': 10.0, 'randomforestclassifier__n_estimators': 10}\n",
      "0.868 +/- 0.00 {'kneighborsclassifier__n_neighbors': 1, 'meta-logisticregression__C': 10.0, 'randomforestclassifier__n_estimators': 200}\n",
      "0.837 +/- 0.00 {'kneighborsclassifier__n_neighbors': 5, 'meta-logisticregression__C': 0.1, 'randomforestclassifier__n_estimators': 10}\n",
      "0.871 +/- 0.00 {'kneighborsclassifier__n_neighbors': 5, 'meta-logisticregression__C': 0.1, 'randomforestclassifier__n_estimators': 200}\n",
      "0.835 +/- 0.00 {'kneighborsclassifier__n_neighbors': 5, 'meta-logisticregression__C': 10.0, 'randomforestclassifier__n_estimators': 10}\n",
      "0.868 +/- 0.00 {'kneighborsclassifier__n_neighbors': 5, 'meta-logisticregression__C': 10.0, 'randomforestclassifier__n_estimators': 200}\n",
      "Best parameters: {'kneighborsclassifier__n_neighbors': 5, 'meta-logisticregression__C': 0.1, 'randomforestclassifier__n_estimators': 200}\n",
      "Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=lr)\n",
    "\n",
    "logger.info('3-fold cross validation:\\n')\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "          'randomforestclassifier__n_estimators': [10, 200],\n",
    "          'meta-logisticregression__C': [0.1, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True,\n",
    "                    scoring='roc_auc')\n",
    "grid.fit(train_dataset_x, train_dataset_y)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='a...e=False, random_state=0, verbose=0, warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)],\n",
       "          meta_classifier=LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False),\n",
       "          store_train_meta_features=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf2 = RandomForestClassifier(random_state=0, n_estimators=200)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression(solver='lbfgs', class_weight='balanced', multi_class='multinomial', C=0.1)\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=lr)\n",
    "\n",
    "sclf.fit(train_dataset_x, train_dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def evaluate(result_df):\n",
    "    group = result_df.groupby(['Coupon_id'])\n",
    "    aucs = []\n",
    "    for i in group:\n",
    "        tmpdf = i[1]        \n",
    "        if len(tmpdf['Label'].unique()) != 2:\n",
    "            continue\n",
    "            \n",
    "        fpr, tpr, thresholds = roc_curve(tmpdf['Label'], tmpdf['Prob'], pos_label=1)\n",
    "        auc_score = auc(fpr,tpr)\n",
    "        aucs.append(auc_score)\n",
    "            \n",
    "    return np.average(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987197678112163"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test_prob_y = sclf.predict_proba(valid_dataset_x)\n",
    "dataset_alpha['Prob'] = predict_test_prob_y[:, 1]\n",
    "evaluate(dataset_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
