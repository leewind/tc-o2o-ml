{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from pyfm import pylibfm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_df = pd.read_csv('ccf_offline_stage1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = offline_df[offline_df['Date_received']<20160501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DayInMonth4ReceivedDayExtractor(TransformerMixin):\n",
    "    def get_day_in_month_4_received_day(self, received_date):\n",
    "        if math.isnan(received_date) or isinstance(received_date, int) or float(received_date) <= 0:\n",
    "            return 0.0\n",
    "\n",
    "        date_received = datetime.strptime(str(int(received_date)), '%Y%m%d')\n",
    "        return date_received.day\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(X['Date_received'].apply(lambda row: self.get_day_in_month_4_received_day(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayInWeek4ReceivedDayExtractor(TransformerMixin):\n",
    "    def get_day_in_week_4_received_day(self, received_date):\n",
    "        if math.isnan(received_date) or isinstance(received_date, int) or float(received_date) <= 0:\n",
    "            return 0.0\n",
    "\n",
    "        date_received = datetime.strptime(str(int(received_date)), '%Y%m%d')\n",
    "        return (date_received.weekday() + 1)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(X['Date_received'].apply(lambda row: self.get_day_in_week_4_received_day(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConsumeExtractor(TransformerMixin):\n",
    "    def base_consume(self, discount_rate):\n",
    "        if isinstance(discount_rate, int):\n",
    "            return float(discount_rate)\n",
    "\n",
    "        if isinstance(discount_rate, float):\n",
    "            return discount_rate\n",
    "\n",
    "        if discount_rate == 'fixed':\n",
    "            return 0.0\n",
    "\n",
    "        arr = discount_rate.split(':')\n",
    "        if len(arr) == 2:\n",
    "            return float(arr[0])\n",
    "        else:\n",
    "            return 0.0\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(X['Discount_rate'].apply(lambda row: self.base_consume(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscountExtractor(TransformerMixin):\n",
    "    def cal_discount(self, discount_rate):\n",
    "        if isinstance(discount_rate, int):\n",
    "            return float(discount_rate)\n",
    "\n",
    "        if isinstance(discount_rate, float):\n",
    "            return discount_rate\n",
    "\n",
    "        if discount_rate == 'fixed':\n",
    "            return 0.0\n",
    "\n",
    "        arr = discount_rate.split(':')\n",
    "        if len(arr) == 2:\n",
    "            return (float(arr[0]) - float(arr[1])) / float(arr[0])\n",
    "        else:\n",
    "            return float(discount_rate)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(X['Discount_rate'].apply(lambda row: self.cal_discount(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouponTypeExtractor(TransformerMixin):\n",
    "    def set_coupon_type(self, discount_rate):\n",
    "        if isinstance(discount_rate, int):\n",
    "            return 1\n",
    "\n",
    "        if isinstance(discount_rate, float):\n",
    "            return 1\n",
    "\n",
    "        if discount_rate == 'fixed':\n",
    "            return 2\n",
    "\n",
    "        arr = discount_rate.split(':')\n",
    "        if len(arr) == 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return pd.DataFrame(X['Discount_rate'].apply(lambda row: self.set_coupon_type(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelExtractor(TransformerMixin):\n",
    "    def check_is_in_day_consume(self, row):\n",
    "        if row['Coupon_id'] == 'fixed':\n",
    "            return 0\n",
    "\n",
    "        if float(row['Coupon_id']) > 0 and float(row['Date_received']) > 0 and float(row['Date']) > 0:\n",
    "            date_received = datetime.strptime(str(int(row['Date_received'])), '%Y%m%d')\n",
    "            date_consumed = datetime.strptime(str(int(row['Date'])), '%Y%m%d')\n",
    "            delta = date_consumed - date_received\n",
    "            if delta.days < 16:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X.apply(lambda row: self.check_is_in_day_consume(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "class DictTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = DictVectorizer()\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vectorizer.fit(pd.DataFrame(X).T.to_dict().values())\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.vectorizer.transform(pd.DataFrame(X).T.to_dict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Pipeline构建特征的抽取和模型训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: 0.18203\n",
      "-- Epoch 2\n",
      "Training log loss: 0.16962\n",
      "-- Epoch 3\n",
      "Training log loss: 0.16803\n",
      "-- Epoch 4\n",
      "Training log loss: 0.16726\n",
      "-- Epoch 5\n",
      "Training log loss: 0.16680\n",
      "-- Epoch 6\n",
      "Training log loss: 0.16653\n",
      "-- Epoch 7\n",
      "Training log loss: 0.16634\n",
      "-- Epoch 8\n",
      "Training log loss: 0.16622\n",
      "-- Epoch 9\n",
      "Training log loss: 0.16612\n",
      "-- Epoch 10\n",
      "Training log loss: 0.16605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('continuous', Pipeline(memory=None,\n",
       "     steps=[('base_consume', <__main__.BaseConsumeExtractor object at 0x10d986400>), ('discount', <__main__.DiscountExtractor object at 0x10d986470>), ('imputer', SimpleImputer(copy=True, fill... <__main__.DictTransformer object at 0x10d986940>), ('fm', <pyfm.pylibfm.FM object at 0x10d9869b0>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACTOR_FIELDS = ['Distance']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('base_consume', BaseConsumeExtractor()),\n",
    "            ('discount', DiscountExtractor()),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "            ('scale', Normalizer())\n",
    "        ])),\n",
    "        ('distance', Pipeline([\n",
    "            ('extract', ColumnSelector(FACTOR_FIELDS)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "            ('one_hot', OneHotEncoder(categories='auto')),\n",
    "            ('to_dense', DenseTransformer())\n",
    "        ])),\n",
    "        ('coupon_type', Pipeline([\n",
    "            ('extract', CouponTypeExtractor()),\n",
    "            ('one_hot', OneHotEncoder(categories='auto')),\n",
    "            ('to_dense', DenseTransformer())\n",
    "        ])),\n",
    "        ('day_in_week', Pipeline([\n",
    "            ('extract', DayInWeek4ReceivedDayExtractor()),\n",
    "            ('one_hot', OneHotEncoder(categories='auto')),\n",
    "            ('to_dense', DenseTransformer())\n",
    "        ])),\n",
    "        ('day_in_month', Pipeline([\n",
    "            ('extract', DayInMonth4ReceivedDayExtractor()),\n",
    "            ('one_hot', OneHotEncoder(categories='auto')),\n",
    "            ('to_dense', DenseTransformer())\n",
    "        ])),\n",
    "    ])),\n",
    "    ('dict', DictTransformer()),\n",
    "    ('fm', pylibfm.FM(num_factors=128, num_iter=10, verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\"))\n",
    "])\n",
    "\n",
    "labelextractor = LabelExtractor()\n",
    "label_dataset = labelextractor.transform(train_dataset)\n",
    "\n",
    "pipeline.fit(train_dataset, label_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = offline_df[offline_df['Date_received']>=20160501]\n",
    "test_dataset = test_dataset[test_dataset['Coupon_id']>0]\n",
    "test_label_dataset = labelextractor.transform(test_dataset)\n",
    "\n",
    "prediction = pipeline.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用特征工程训练好的数据，直接用Pipeline构建模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('lcm_train_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Is_in_day_consume']\n",
    "FEATURES = ['Distance','Previous_duration',\n",
    "       'Next_duration', 'Base_consume', 'Day_in_month_received',\n",
    "       'Day_in_week_received', 'Discount', 'Coupon_type', 'User_receive_count', 'User_consume_count',\n",
    "       'User_used_count', 'User_not_used_count', 'User_used_coupon_rate',\n",
    "       'User_used_coupon_rate_max', 'User_used_coupon_rate_min',\n",
    "       'User_used_coupon_rate_mean', 'User_receive_coupon_merchant_count',\n",
    "       'User_consume_merchant_count', 'User_used_coupon_merchant_count',\n",
    "       'User_used_coupon_merchant_occ',\n",
    "       'User_receive_different_coupon_count',\n",
    "       'User_used_different_coupon_count',\n",
    "       'User_receive_different_coupon_occ',\n",
    "       'User_used_different_coupon_occ', 'User_receive_coupon_mean',\n",
    "       'User_used_coupon_mean', 'User_distance_used_mean',\n",
    "       'User_distance_used_max', 'User_distance_used_min',\n",
    "       'User_duration_used_mean', 'User_duration_used_max',\n",
    "       'User_duration_used_min', 'User_previous_duration_used_mean',\n",
    "       'User_previous_duration_used_max',\n",
    "       'User_previous_duration_used_min', 'User_next_duration_used_mean',\n",
    "       'User_next_duration_used_max', 'User_next_duration_used_min',\n",
    "       'Merchant_receive_count', 'Merchant_consume_count',\n",
    "       'Merchant_used_count', 'Merchant_not_used_count',\n",
    "       'Merchant_used_coupon_rate', 'Merchant_used_coupon_rate_max',\n",
    "       'Merchant_used_coupon_rate_min', 'Merchant_used_coupon_rate_mean',\n",
    "       'Merchant_receive_coupon_user_count',\n",
    "       'Merchant_consume_user_count', 'Merchant_used_coupon_user_count',\n",
    "       'Merchant_receive_coupon_user_occ', 'Merchant_consume_user_occ',\n",
    "       'Merchant_used_coupon_user_occ',\n",
    "       'Merchant_receive_different_coupon_count',\n",
    "       'Merchant_used_different_coupon_count',\n",
    "       'Merchant_receive_different_coupon_occ',\n",
    "       'Merchant_used_different_coupon_occ',\n",
    "       'Merchant_receive_coupon_mean', 'Merchant_used_coupon_mean',\n",
    "       'Merchant_receive_different_coupon_avg',\n",
    "       'Merchant_used_different_coupon_avg',\n",
    "       'Merchant_distance_used_mean', 'Merchant_distance_used_max',\n",
    "       'Merchant_distance_used_min', 'Merchant_duration_used_mean',\n",
    "       'Merchant_duration_used_max', 'Merchant_duration_used_min',\n",
    "       'Merchant_previous_duration_used_mean',\n",
    "       'Merchant_previous_duration_used_max',\n",
    "       'Merchant_previous_duration_used_min',\n",
    "       'Merchant_next_duration_used_mean',\n",
    "       'Merchant_next_duration_used_max',\n",
    "       'Merchant_next_duration_used_min', 'Coupon_received_count',\n",
    "       'Coupon_used_count', 'Coupon_used_rate',\n",
    "       'Coupon_duration_used_mean', 'Coupon_duration_used_max',\n",
    "       'Coupon_duration_used_min', 'Coupon_distance_used_mean',\n",
    "       'Coupon_distance_used_max', 'Coupon_distance_used_min',\n",
    "       'User_merchant_receive_count', 'User_merchant_consume_count',\n",
    "       'User_merchant_used_count', 'User_merchant_not_used_count',\n",
    "       'User_merchant_used_coupon_rate',\n",
    "       'User_merchant_not_used_coupon_rate',\n",
    "       'User_merchant_used_coupon_rate_4_merchant',\n",
    "       'User_merchant_not_used_coupon_rate_4_merchant',\n",
    "       'User_merchant_duration_used_mean',\n",
    "       'User_merchant_duration_used_max',\n",
    "       'User_merchant_duration_used_min', 'Online_user_receive_count',\n",
    "       'Online_user_consume_count', 'Online_user_used_count',\n",
    "       'Online_user_not_used_count', 'Online_user_used_coupon_rate',\n",
    "       'User_offline_consume_rate', 'User_offline_used_rate',\n",
    "       'User_offline_no_consume_coupon_rate',\n",
    "       'User_distance_receive_count', 'User_distance_consume_count',\n",
    "       'User_distance_used_count', 'User_distance_receive_rate',\n",
    "       'User_distance_consume_rate', 'User_distance_used_rate',\n",
    "       'User_coupon_type_receive_count', 'User_coupon_type_used_count',\n",
    "       'User_coupon_type_receive_rate', 'User_coupon_type_used_rate',\n",
    "       'User_coupon_receive_count', 'User_coupon_used_count',\n",
    "       'User_coupon_receive_rate', 'User_coupon_used_rate',\n",
    "       'Merchant_distance_receive_count',\n",
    "       'Merchant_distance_consume_count', 'Merchant_distance_used_count',\n",
    "       'Merchant_distance_receive_rate', 'Merchant_distance_used_rate',\n",
    "       'User_coupon_duration_used_mean', 'User_coupon_duration_used_max',\n",
    "       'User_coupon_duration_used_min', 'User_received_date_count']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "#     ('features', FeatureUnion([\n",
    "#         ('extract', ColumnSelector(FEATURES)),\n",
    "#         ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "#     ])),\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "    ('dict', DictVectorizer()),\n",
    "    ('fm', pylibfm.FM(num_factors=10, num_iter=10, verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\"))\n",
    "])\n",
    "\n",
    "features_dict = train_dataset[FEATURES].T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "pipeline.fit(features_dict, train_dataset[LABELS].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py, 6): no suitable image found.  Did find:\n\t/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py: file too short\n\t/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py: file too short",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e66f663d4e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mffm_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFMData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mffm_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFFMData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mffm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFFMData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFFM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpd2ffm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFFMFormatPandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_libffm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_libffm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/ffm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mFFM_Float_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0m_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffm_convert_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFM_Problem_ptr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py, 6): no suitable image found.  Did find:\n\t/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py: file too short\n\t/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ffm-1.0-py3.7-macosx-10.14-x86_64.egg/ffm/libffm.py: file too short"
     ]
    }
   ],
   "source": [
    "import ffm\n",
    "\n",
    "ffm_dataset = ffm.FFMData(train_dataset[FEATURES], train_dataset[LABELS])\n",
    "ffm_test_dataset = ffm.FFMData(train_dataset[FEATURES], train_dataset[LABELS])\n",
    "    \n",
    "# train the model for 10 iterations \n",
    "clf = ffm.FFM(eta=0.1, lam=0.0001, k=4)\n",
    "clf.fit(ffm_data,num_iter=10, val_data=ffm_data_test, metric='auc', early_stopping=6, maximum=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FEATURES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f10b628ac522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lcm_train_test_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coupon_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FEATURES' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('lcm_train_test_features.csv')\n",
    "test_dataset = test_dataset[test_dataset['Coupon_id']>0]\n",
    "test_dict = test_dataset[FEATURES].T.to_dict().values()\n",
    "prediction = fm.predict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def evaluate(result_df):\n",
    "    group = result_df.groupby(['Coupon_id'])\n",
    "    aucs = []\n",
    "    for i in group:\n",
    "        tmpdf = i[1]        \n",
    "        if len(tmpdf['Is_in_day_consume'].unique()) != 2:\n",
    "            continue\n",
    "            \n",
    "        fpr, tpr, thresholds = roc_curve(tmpdf['Is_in_day_consume'], tmpdf['Probability'], pos_label=1)\n",
    "        auc_score = auc(fpr,tpr)\n",
    "        aucs.append(auc_score)\n",
    "            \n",
    "    return np.average(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df = test_dataset.copy()\n",
    "test_result_df['Probability'] = prediction\n",
    "test_result_df['Is_in_day_consume'] = test_label_dataset\n",
    "evaluate(test_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
