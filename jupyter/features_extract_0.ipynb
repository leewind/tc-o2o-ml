{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby2df(t, name):\n",
    "    t = t.to_frame()\n",
    "    t.columns = [name]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_df = pd.read_csv('../source/ccf_offline_stage1_train.csv', parse_dates = ['Date_received', 'Date'])\n",
    "online_df = pd.read_csv('../source/ccf_online_stage1_train.csv', parse_dates = ['Date_received', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('../source/ccf_offline_stage1_test_revised.csv', parse_dates = ['Date_received'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = [datetime.datetime(2016, 5, 16), datetime.datetime(2016, 6, 15)]\n",
    "\n",
    "time_range_date_received = [datetime.datetime(2016, 2, 1), datetime.datetime(2016, 4, 30)]\n",
    "time_range_date = [datetime.datetime(2016, 2, 1), datetime.datetime(2016, 5, 15)]\n",
    "\n",
    "FILENAME = 'dataset_beta'\n",
    "\n",
    "IS_PRED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_range = [datetime.datetime(2016, 4, 16), datetime.datetime(2016, 5, 15)]\n",
    "\n",
    "# time_range_date_received = [datetime.datetime(2016, 1, 1), datetime.datetime(2016, 3, 31)]\n",
    "# time_range_date = [datetime.datetime(2016, 1, 1), datetime.datetime(2016, 4, 15)]\n",
    "\n",
    "# FILENAME = 'dataset_alpha'\n",
    "\n",
    "# IS_PRED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(row, time_range_date_received, time_range_date):\n",
    "    if ((row.Date >= time_range_date[0]) & (row.Date <= time_range_date[1])) | ((row.Coupon_id == 0) & (row.Date_received >= time_range_date_received[0]) & (row.Date_received <= time_range_date_received[1])):\n",
    "        return row\n",
    "    \n",
    "def dataset_fetch(time_range):\n",
    "    dataset = offline_df[(offline_df.Date_received >= time_range[0]) & (offline_df.Date_received <= time_range[1])].copy()\n",
    "    return dataset\n",
    "    \n",
    "def dataset_split(time_range_date_received, time_range_date):\n",
    "    feature_offline = offline_df.loc[\n",
    "        ((offline_df.Date >= time_range_date[0]) & (offline_df.Date <= time_range_date[1])) | \n",
    "        ((offline_df.Coupon_id == 0) & (offline_df.Date_received >= time_range_date_received[0]) & (offline_df.Date_received <= time_range_date_received[1]))]\n",
    "    feature_online = online_df.loc[\n",
    "        ((online_df.Date >= time_range_date[0]) & (online_df.Date <= time_range_date[1])) | \n",
    "        ((online_df.Coupon_id == 0) & (online_df.Date_received >= time_range_date_received[0]) & (online_df.Date_received <= time_range_date_received[1]))]\n",
    "    \n",
    "    return feature_offline, feature_online\n",
    "\n",
    "if IS_PRED:\n",
    "    dataset = pred_df\n",
    "else:\n",
    "    dataset = dataset_fetch(time_range)\n",
    "\n",
    "feature_alpha_offline, feature_alpha_online = dataset_split(time_range_date_received, time_range_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础数据特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_cat = offline_df['Discount_rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_coupon_feature(row):\n",
    "    if isinstance(row.Discount_rate, str) and row.Discount_rate == 'fixed':\n",
    "        row.Coupon_type = 2\n",
    "        return row\n",
    "    \n",
    "    if isinstance(row.Discount_rate, float):\n",
    "        row.Discount = row.Discount_rate\n",
    "        i, = np.where(discount_cat == row.Discount_rate)\n",
    "        if len(i)>0:\n",
    "            row.Coupon_category = i[0]\n",
    "        return row\n",
    "    \n",
    "    arr = row.Discount_rate.split(':')\n",
    "    if len(arr) == 2:\n",
    "        row.Discount =  (float(arr[0]) - float(arr[1])) / float(arr[0])\n",
    "        row.Coupon_type = 1\n",
    "        row.Base_consume = float(arr[0])\n",
    "        row.Discount_money = float(arr[1])\n",
    "    else:\n",
    "        row.Discount = float(row.Discount_rate)\n",
    "        \n",
    "    i, = np.where(discount_cat == row.Discount_rate)\n",
    "    if len(i)>0:\n",
    "        row.Coupon_category = i[0]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_previous_duration(row):\n",
    "    if row['User_id'] == row['Previous_user_id'] and row['Date_received'] is not None and row['Previous_date_received'] is not None:\n",
    "        return (row.Date_received - row.Previous_date_received).days\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def cal_next_duration(row):\n",
    "    if row['User_id'] == row['Next_user_id'] and row['Date_received'] is not None and row['Next_date_received'] is not None:\n",
    "        return (row.Next_date_received - row.Date_received).days\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_info(dataset):\n",
    "    dataset['Distance'] = dataset['Distance'].fillna(-1)\n",
    "    dataset['Distance'] = dataset['Distance'] + 1\n",
    "\n",
    "    dataset['Month_of_received'] = dataset.apply(lambda row: row.Date_received.month, axis=1)\n",
    "    dataset['Day_of_received'] = dataset.apply(lambda row: row.Date_received.day, axis=1)\n",
    "    dataset['Weekday_of_received'] = dataset.apply(lambda row: row.Date_received.weekday() + 1, axis=1)\n",
    "\n",
    "    dataset['Base_consume'] = 0.0\n",
    "    dataset['Discount'] = 0.0\n",
    "    dataset['Discount_money'] = 0.0\n",
    "    dataset['Coupon_type'] = 0\n",
    "    dataset['Coupon_category'] = 0\n",
    "\n",
    "    dataset = dataset.apply(lambda row: cal_coupon_feature(row), axis=1)\n",
    "\n",
    "    dataset = dataset.sort_values(by=['User_id', 'Date_received'], ascending=True)\n",
    "\n",
    "    dataset['Previous_user_id'] = dataset['User_id'].shift(1)\n",
    "    dataset['Previous_date_received'] = dataset['Date_received'].shift(1)\n",
    "\n",
    "    dataset['Next_user_id'] = dataset['User_id'].shift(-1)\n",
    "    dataset['Next_date_received'] = dataset['Date_received'].shift(-1)\n",
    "\n",
    "    dataset['Previous_duration'] = dataset.apply(lambda row: cal_previous_duration(row), axis=1)\n",
    "    dataset['Next_duration'] = dataset.apply(lambda row: cal_next_duration(row), axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = extract_basic_info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month_of_received</th>\n",
       "      <th>Day_of_received</th>\n",
       "      <th>Weekday_of_received</th>\n",
       "      <th>...</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Discount_money</th>\n",
       "      <th>Coupon_type</th>\n",
       "      <th>Coupon_category</th>\n",
       "      <th>Previous_user_id</th>\n",
       "      <th>Previous_date_received</th>\n",
       "      <th>Next_user_id</th>\n",
       "      <th>Next_date_received</th>\n",
       "      <th>Previous_duration</th>\n",
       "      <th>Next_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679793</th>\n",
       "      <td>4</td>\n",
       "      <td>1469</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95903</th>\n",
       "      <td>165</td>\n",
       "      <td>4195</td>\n",
       "      <td>7571.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679003</th>\n",
       "      <td>166</td>\n",
       "      <td>484</td>\n",
       "      <td>9261.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264361</th>\n",
       "      <td>215</td>\n",
       "      <td>129</td>\n",
       "      <td>8944.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>236.0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263171</th>\n",
       "      <td>236</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id Discount_rate  Distance  \\\n",
       "679793         4         1469     2902.0          0.95      11.0   \n",
       "95903        165         4195     7571.0          30:5       1.0   \n",
       "679003       166          484     9261.0          20:1       0.0   \n",
       "1264361      215          129     8944.0          30:5       2.0   \n",
       "1263171      236         4663    11002.0        150:20       3.0   \n",
       "\n",
       "        Date_received Date  Month_of_received  Day_of_received  \\\n",
       "679793     2016-06-07  NaT                  6                7   \n",
       "95903      2016-05-25  NaT                  5               25   \n",
       "679003     2016-05-25  NaT                  5               25   \n",
       "1264361    2016-05-24  NaT                  5               24   \n",
       "1263171    2016-05-28  NaT                  5               28   \n",
       "\n",
       "         Weekday_of_received      ...        Discount  Discount_money  \\\n",
       "679793                     2      ...        0.950000             0.0   \n",
       "95903                      3      ...        0.833333             5.0   \n",
       "679003                     3      ...        0.950000             1.0   \n",
       "1264361                    2      ...        0.833333             5.0   \n",
       "1263171                    6      ...        0.866667            20.0   \n",
       "\n",
       "         Coupon_type  Coupon_category  Previous_user_id  \\\n",
       "679793             0               21               NaN   \n",
       "95903              1                4               4.0   \n",
       "679003             1                2             165.0   \n",
       "1264361            1                4             166.0   \n",
       "1263171            1                1             215.0   \n",
       "\n",
       "         Previous_date_received Next_user_id  Next_date_received  \\\n",
       "679793                      NaT        165.0          2016-05-25   \n",
       "95903                2016-06-07        166.0          2016-05-25   \n",
       "679003               2016-05-25        215.0          2016-05-24   \n",
       "1264361              2016-05-25        236.0          2016-05-28   \n",
       "1263171              2016-05-24        238.0          2016-06-08   \n",
       "\n",
       "        Previous_duration  Next_duration  \n",
       "679793                  0              0  \n",
       "95903                   0              0  \n",
       "679003                  0              0  \n",
       "1264361                 0              0  \n",
       "1263171                 0              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测区间特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o1**: 用户在预测区获取的优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o1'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o2**: 用户平均15天领取的优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o2'] = d['o1'] / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o3**: 用户平均每天领取多少张优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = d[['User_id', 'o1']].drop_duplicates()\n",
    "\n",
    "t = d.groupby('User_id')['Date_received'].max()\n",
    "u = pd.merge(u, groupby2df(t, 'r_max'), on=['User_id'], how='left')\n",
    "\n",
    "t = d.groupby('User_id')['Date_received'].min()\n",
    "u = pd.merge(u, groupby2df(t, 'r_min'), on=['User_id'], how='left')\n",
    "\n",
    "u['r_day_duration'] = u.apply(lambda row: (row['r_max'] - row['r_min']).days, axis=1)\n",
    "u['o3'] = u['o1'] / u['r_day_duration']\n",
    "d = pd.merge(d, u[['User_id', 'o3']], on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o4**:预测区用户每种类型优惠券领取的数量\n",
    "+ **特征o5**:预测区用户每种类型优惠券领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_category']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o4'), on=['User_id', 'Coupon_category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o5'] = d['o4'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o6**:预测区用户领取优惠券Coupon_id领取的数量\n",
    "+ **特征o8**:预测区用户领取优惠券Coupon_id领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o6'), on=['User_id', 'Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o8'] = d['o6'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o7**:预测区用户领取优惠券Coupon_id在领取日领取的数量\n",
    "+ **特征o9**:预测区用户领取优惠券Coupon_id在领取日领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_id', 'Date_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o7'), on=['User_id', 'Coupon_id', 'Date_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o9'] = d['o7'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o10**:预测区用户领取多少种不同的优惠券\n",
    "+ **特征o14**:预测区用户平均每个领取的优惠券领取了多少张\n",
    "+ **特征o12**:预测区用户领取的不同的优惠券占所有优惠券的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['User_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o10'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o12'] = d['o10'] / d['Coupon_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o14'] = d['o1'] / d['o10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o11**:预测区每种优惠券被领取的张数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o11'), on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o13**:预测区用户领取的不同的商户数\n",
    "+ **特征o16**:预测区用户领取的不同的商户数占所有商户数的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['User_id', 'Merchant_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o13'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o16'] = d['o13'] / d['Merchant_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o15**:预测区用户在每个消费的商户领取的优惠券数\n",
    "+ **特征o18**:预测区用户在每个消费的商户领取的优惠券数在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o15'), on=['User_id', 'Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o18'] = d['o15'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o19**:预测区用户在每个距离上领取的优惠券数量\n",
    "+ **特征o20**:预测区用户在每个距离上领取的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Distance']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o19'), on=['User_id', 'Distance'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o20'] = d['o19'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o21 - o23** 用户领取的优惠券距离最大、最小、平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].max()\n",
    "d = pd.merge(d, groupby2df(t, 'o21'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].min()\n",
    "d = pd.merge(d, groupby2df(t, 'o22'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].mean()\n",
    "d = pd.merge(d, groupby2df(t, 'o23'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o17**:预测区用户领取的不同的优惠券分类的优惠券数量\n",
    "+ **特征o24**:预测区用户领取的不同的优惠券分类的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Coupon_type']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o17'), on=['User_id', 'Coupon_type'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o24'] = d['o17'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o25**:预测区用户在领取日领取的优惠券数量\n",
    "+ **特征o26**:预测区用户在领取日领取的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Date_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o25'), on=['User_id', 'Date_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o26'] = d['o25'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o27 - o29**用户优惠券折扣的最大、最小、平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].mean()\n",
    "d = pd.merge(d, groupby2df(t, 'o27'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].max()\n",
    "d = pd.merge(d, groupby2df(t, 'o28'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].min()\n",
    "d = pd.merge(d, groupby2df(t, 'o29'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o30**:预测区每个商户被领用的优惠券数量\n",
    "+ **特征o38**:预测区每个商户平均被每个用户领取的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o30'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o38'] = d['o30'] / d['User_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o31**:预测区用户在每周不同的weekday领取优惠券的数量\n",
    "+ **特征o39**:预测区用户在每周不同的weekday领取优惠券的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Weekday_of_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o31'), on=['User_id', 'Weekday_of_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o39'] = d['o31'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o32**:预测区商户被多少不同用户领取\n",
    "+ **特征o33**:预测区商户被不同用户平均领取优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Merchant_id', 'User_id']].drop_duplicates()\n",
    "t = t.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o32'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o33'] = d['o30'] / d['o32']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o34**:每家商户有多少张不同的优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Merchant_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o34'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o35**:每张优惠券被多少不同的人领取了\n",
    "+ **特征o36**:每张优惠券平均被每个领用的用户领取了多少张\n",
    "+ **特征o37**:每张优惠券平均被每个用户领取了多少张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Coupon_id', 'User_id']].drop_duplicates()\n",
    "t = t.groupby(['Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o35'), on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o36'] = d['o11'] / d['o35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o37'] = d['o11'] / d['User_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_PRED:\n",
    "    dataset['Duration'] = dataset.apply(lambda row: (row['Date'] - row['Date_received']).days, axis=1)\n",
    "    dataset['Label'] = dataset.apply(lambda row: 1 if row['Duration'] < 16 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month_of_received</th>\n",
       "      <th>Day_of_received</th>\n",
       "      <th>Weekday_of_received</th>\n",
       "      <th>...</th>\n",
       "      <th>o31</th>\n",
       "      <th>o39</th>\n",
       "      <th>o32</th>\n",
       "      <th>o33</th>\n",
       "      <th>o34</th>\n",
       "      <th>o35</th>\n",
       "      <th>o36</th>\n",
       "      <th>o37</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1469</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10308</td>\n",
       "      <td>1.175786</td>\n",
       "      <td>8</td>\n",
       "      <td>492</td>\n",
       "      <td>1.034553</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>4195</td>\n",
       "      <td>7571.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>269</td>\n",
       "      <td>1.200743</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>1.200743</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166</td>\n",
       "      <td>484</td>\n",
       "      <td>9261.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215</td>\n",
       "      <td>129</td>\n",
       "      <td>8944.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>553</td>\n",
       "      <td>1.099458</td>\n",
       "      <td>1</td>\n",
       "      <td>553</td>\n",
       "      <td>1.099458</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>236</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>150:20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10771</td>\n",
       "      <td>1.005571</td>\n",
       "      <td>2</td>\n",
       "      <td>7730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>238</td>\n",
       "      <td>760</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-06-08</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30614</td>\n",
       "      <td>1.023976</td>\n",
       "      <td>7</td>\n",
       "      <td>29269</td>\n",
       "      <td>1.000512</td>\n",
       "      <td>0.170246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>239</td>\n",
       "      <td>3465</td>\n",
       "      <td>9762.0</td>\n",
       "      <td>10:1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>239</td>\n",
       "      <td>3465</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>10:1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>315</td>\n",
       "      <td>3621</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13923</td>\n",
       "      <td>1.246211</td>\n",
       "      <td>9</td>\n",
       "      <td>1283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>315</td>\n",
       "      <td>3621</td>\n",
       "      <td>4033.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13923</td>\n",
       "      <td>1.246211</td>\n",
       "      <td>9</td>\n",
       "      <td>2666</td>\n",
       "      <td>1.036759</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance Date_received Date  \\\n",
       "0        4         1469     2902.0          0.95      11.0    2016-06-07  NaT   \n",
       "1      165         4195     7571.0          30:5       1.0    2016-05-25  NaT   \n",
       "2      166          484     9261.0          20:1       0.0    2016-05-25  NaT   \n",
       "3      215          129     8944.0          30:5       2.0    2016-05-24  NaT   \n",
       "4      236         4663    11002.0        150:20       3.0    2016-05-28  NaT   \n",
       "5      238          760     2418.0          30:5       5.0    2016-06-08  NaT   \n",
       "6      239         3465     9762.0          10:1      11.0    2016-06-14  NaT   \n",
       "7      239         3465     1255.0          10:1      11.0    2016-06-14  NaT   \n",
       "8      315         3621     1141.0          20:5       2.0    2016-05-18  NaT   \n",
       "9      315         3621     4033.0          20:5       2.0    2016-05-19  NaT   \n",
       "\n",
       "   Month_of_received  Day_of_received  Weekday_of_received  ...    o31  o39  \\\n",
       "0                  6                7                    2  ...      1  1.0   \n",
       "1                  5               25                    3  ...      1  1.0   \n",
       "2                  5               25                    3  ...      1  1.0   \n",
       "3                  5               24                    2  ...      1  1.0   \n",
       "4                  5               28                    6  ...      1  1.0   \n",
       "5                  6                8                    3  ...      1  1.0   \n",
       "6                  6               14                    2  ...      2  1.0   \n",
       "7                  6               14                    2  ...      2  1.0   \n",
       "8                  5               18                    3  ...      1  0.5   \n",
       "9                  5               19                    4  ...      1  0.5   \n",
       "\n",
       "     o32       o33  o34    o35       o36       o37 Duration  Label  \n",
       "0  10308  1.175786    8    492  1.034553  0.002959      NaN      0  \n",
       "1    269  1.200743    1    269  1.200743  0.001878      NaN      0  \n",
       "2      4  1.000000    1      4  1.000000  0.000023      NaN      0  \n",
       "3    553  1.099458    1    553  1.099458  0.003535      NaN      0  \n",
       "4  10771  1.005571    2   7730  1.000000  0.044939      NaN      0  \n",
       "5  30614  1.023976    7  29269  1.000512  0.170246      NaN      0  \n",
       "6      5  1.600000    2      4  1.000000  0.000023      NaN      0  \n",
       "7      5  1.600000    2      4  1.000000  0.000023      NaN      0  \n",
       "8  13923  1.246211    9   1283  1.000000  0.007459      NaN      0  \n",
       "9  13923  1.246211    9   2666  1.036759  0.016069      NaN      0  \n",
       "\n",
       "[10 rows x 62 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(df, keys, suffix):\n",
    "    t = receive.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'1'), on=keys, how='left')\n",
    "\n",
    "    t = consume.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'2'), on=keys, how='left')\n",
    "\n",
    "    t = use.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'3'), on=keys, how='left')\n",
    "\n",
    "    df[suffix+'4'] = df[suffix+'1'] - df[suffix+'3']\n",
    "    df[suffix+'5'] = df[suffix+'1'] - df[suffix+'2']\n",
    "    \n",
    "    df[suffix+'6'] = df[suffix+'3'] / df[suffix+'4']\n",
    "    df[suffix+'7'] = df[suffix+'2'] / df[suffix+'5']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mean_max_min(d, df, keys, column_name, prefix, count):\n",
    "    t = d.groupby(keys)[column_name].mean()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "\n",
    "    count = count + 1\n",
    "    t = d.groupby(keys)[column_name].max()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "\n",
    "    count = count + 1\n",
    "    t = d.groupby(keys)[column_name].min()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分特征数据集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_alpha_offline = extract_basic_info(feature_alpha_offline)\n",
    "\n",
    "feature_alpha_offline['Duration'] = feature_alpha_offline.apply(lambda row: (row['Date'] - row['Date_received']).days, axis=1)\n",
    "feature_alpha_offline['Label'] = feature_alpha_offline.apply(lambda row: 1 if row['Duration'] < 16 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "receive = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0]\n",
    "consume = receive[receive['Duration'] >= 0]\n",
    "use = receive[receive['Label']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u1**:用户领取优惠券的数量\n",
    "+ **特征u2**:用户消费优惠券的数量\n",
    "+ **特征u3**:用户15天内消费优惠券的数量\n",
    "+ **特征u4**:用户15天内没有消费优惠券的数量\n",
    "+ **特征u5**:用户用户没有消费优惠券的数量\n",
    "+ **特征u6**:用户15天内消费优惠券的数量 比 用户15天内没有消费优惠券的数量\n",
    "+ **特征u7**:用户消费优惠券的数量 比 用户用户没有消费优惠券的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = get_count(u, ['User_id'], 'u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征8**:用户消费优惠券消费天数的平均值\n",
    "+ **特征9**:用户消费优惠券消费天数的最大值\n",
    "+ **特征10**:用户消费优惠券消费天数的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(consume, u, ['User_id'], 'Duration', 'u', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(consume, u, ['User_id'], 'Discount', 'u', 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = consume[['User_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "u = pd.merge(u, groupby2df(t, 'u14'), on=['User_id'], how='left')\n",
    "\n",
    "t = use[['User_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "u = pd.merge(u, groupby2df(t, 'u15'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = consume[['User_id', 'Merchant_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "u = pd.merge(u, groupby2df(t, 'u16'), on=['User_id'], how='left')\n",
    "\n",
    "t = use[['User_id', 'Merchant_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "u = pd.merge(u, groupby2df(t, 'u17'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "u['u18'] = u['u3'] / u['u1']\n",
    "u['u19'] = u['u2'] / u['u1']\n",
    "\n",
    "u['u20'] = u['u3'] / 15\n",
    "u['u21'] = u['u2'] / 15\n",
    "u['u22'] = u['u1'] / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(use, u, ['User_id'], 'Duration', 'u', 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, u, on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户-优惠券分类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Coupon_category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = get_count(ucc, ['User_id', 'Coupon_category'], 'ucc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = process_mean_max_min(consume, ucc, ['User_id', 'Coupon_category'], 'Duration', 'ucc', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ucc, on=['User_id', 'Coupon_category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ucc11'] = dataset['ucc3'] / dataset['u1']\n",
    "dataset['ucc12'] = dataset['ucc2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户 - 优惠券特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Coupon_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = get_count(uc, ['User_id', 'Coupon_id'], 'uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = process_mean_max_min(consume, uc, ['User_id', 'Coupon_id'], 'Duration', 'uc', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, uc, on=['User_id', 'Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['uc11'] = dataset['uc3'] / dataset['u1']\n",
    "dataset['uc12'] = dataset['uc2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户 - 距离特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Distance']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = get_count(ud, ['User_id', 'Distance'], 'ud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = process_mean_max_min(consume, ud, ['User_id', 'Distance'], 'Duration', 'ud', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ud, on=['User_id', 'Distance'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ud11'] = dataset['ud3'] / dataset['u1']\n",
    "dataset['ud12'] = dataset['ud2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Merchant_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_count(m, ['Merchant_id'], 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = process_mean_max_min(consume, m, ['Merchant_id'], 'Duration', 'm', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, m, on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优惠券特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Coupon_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_count(c, ['Coupon_id'], 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = process_mean_max_min(consume, c, ['Coupon_id'], 'Duration', 'c', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, c, on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线上用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou = feature_alpha_online[['User_id']].drop_duplicates()\n",
    "\n",
    "t = feature_alpha_online.groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou1'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 0].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou2'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 1].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou3'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 2].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou4'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ou, on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造特征选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'Date', 'Month_of_received', 'Day_of_received',\n",
       "       'Weekday_of_received', 'Base_consume', 'Discount',\n",
       "       'Discount_money', 'Coupon_type', 'Coupon_category',\n",
       "       'Previous_user_id', 'Previous_date_received', 'Next_user_id',\n",
       "       'Next_date_received', 'Previous_duration', 'Next_duration', 'o1',\n",
       "       'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
       "       'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
       "       'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
       "       'o30', 'o38', 'o31', 'o39', 'o32', 'o33', 'o34', 'o35', 'o36',\n",
       "       'o37', 'Duration', 'Label', 'u1', 'u2', 'u3', 'u4', 'u5', 'u6',\n",
       "       'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13', 'u14', 'u15', 'u16',\n",
       "       'u17', 'u18', 'u19', 'u20', 'u21', 'u22', 'u23', 'u24', 'u25',\n",
       "       'ucc1', 'ucc2', 'ucc3', 'ucc4', 'ucc5', 'ucc6', 'ucc7', 'ucc8',\n",
       "       'ucc9', 'ucc10', 'ucc11', 'ucc12', 'uc1', 'uc2', 'uc3', 'uc4',\n",
       "       'uc5', 'uc6', 'uc7', 'uc8', 'uc9', 'uc10', 'uc11', 'uc12', 'ud1',\n",
       "       'ud2', 'ud3', 'ud4', 'ud5', 'ud6', 'ud7', 'ud8', 'ud9', 'ud10',\n",
       "       'ud11', 'ud12', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8',\n",
       "       'm9', 'm10', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9',\n",
       "       'c10', 'ou1', 'ou2', 'ou3', 'ou4'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [\n",
    "    'Distance',\n",
    "    'Month_of_received', 'Day_of_received',\n",
    "       'Weekday_of_received', 'Base_consume', 'Discount',\n",
    "       'Discount_money', 'Coupon_type', 'Coupon_category',\n",
    "    'Previous_duration', 'Next_duration', 'o1',\n",
    "       'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
    "       'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
    "       'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
    "       'o30', 'o38', 'o31', 'o39', 'o32', 'o33', 'o34', 'o35', 'o36',\n",
    "       'o37', 'u1', 'u2', 'u3', 'u4', 'u5', 'u6',\n",
    "       'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13', 'u14', 'u15', 'u16',\n",
    "       'u17', 'u18', 'u19', 'u20', 'u21', 'u22', 'u23', 'u24', 'u25',\n",
    "       'ucc1', 'ucc2', 'ucc3', 'ucc4', 'ucc5', 'ucc6', 'ucc7', 'ucc8',\n",
    "       'ucc9', 'ucc10', 'ucc11', 'ucc12', 'uc1', 'uc2', 'uc3', 'uc4',\n",
    "       'uc5', 'uc6', 'uc7', 'uc8', 'uc9', 'uc10', 'uc11', 'uc12', 'ud1',\n",
    "       'ud2', 'ud3', 'ud4', 'ud5', 'ud6', 'ud7', 'ud8', 'ud9', 'ud10',\n",
    "       'ud11', 'ud12', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8',\n",
    "       'm9', 'm10', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9',\n",
    "       'c10', 'ou1', 'ou2', 'ou3', 'ou4']\n",
    "\n",
    "label = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processor = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "#             ('scale', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "            ('normalize', Normalizer())\n",
    "        ])),\n",
    "    ])),\n",
    "#     ('sc4gbdt', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processor.fit(dataset, dataset['Label'].values.ravel())\n",
    "clf = GradientBoostingClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "clf.fit(feature_processor.transform(dataset), dataset['Label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.48438950e-03, 0.00000000e+00, 6.86578135e-04, 0.00000000e+00,\n",
       "       3.11658088e-02, 4.51838101e-03, 9.50587334e-03, 0.00000000e+00,\n",
       "       7.32703232e-03, 2.14992184e-03, 2.18598857e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.58826350e-03, 9.57583859e-02, 7.90730932e-04,\n",
       "       1.29728839e-01, 3.74979374e-03, 0.00000000e+00, 8.82799870e-03,\n",
       "       9.16659781e-03, 0.00000000e+00, 1.55920334e-02, 2.25009897e-02,\n",
       "       7.02043921e-03, 0.00000000e+00, 9.92007051e-02, 6.89961590e-03,\n",
       "       3.41012217e-04, 1.14017600e-03, 2.95846577e-03, 4.56959341e-04,\n",
       "       0.00000000e+00, 1.03818447e-04, 2.07862929e-03, 4.39676927e-04,\n",
       "       2.88753564e-02, 4.63810851e-04, 1.19674656e-03, 7.56511335e-04,\n",
       "       4.90870175e-03, 0.00000000e+00, 0.00000000e+00, 6.82630570e-03,\n",
       "       3.34132402e-02, 4.18031449e-02, 1.56154383e-02, 1.07991843e-02,\n",
       "       5.13550028e-03, 0.00000000e+00, 0.00000000e+00, 4.73155898e-04,\n",
       "       6.39129925e-04, 0.00000000e+00, 0.00000000e+00, 7.11998559e-04,\n",
       "       9.58866852e-05, 2.17466719e-05, 6.69495285e-05, 1.67008540e-03,\n",
       "       0.00000000e+00, 2.07035007e-03, 1.11862571e-04, 2.46454019e-04,\n",
       "       0.00000000e+00, 1.15712567e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.02593869e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.76628436e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.41833615e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.46239894e-03, 4.53248492e-04, 4.99814589e-03, 1.13755710e-04,\n",
       "       0.00000000e+00, 3.31320316e-04, 0.00000000e+00, 4.03590291e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.20515531e-03,\n",
       "       0.00000000e+00, 4.63396138e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.27112381e-04, 1.97753674e-04, 1.14611159e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.27524577e-03,\n",
       "       5.21637904e-04, 0.00000000e+00, 0.00000000e+00, 2.56307178e-02,\n",
       "       4.57838043e-02, 1.28861314e-02, 4.17942088e-03, 0.00000000e+00,\n",
       "       5.32892402e-03, 2.71704595e-04, 5.95383871e-03, 2.45758194e-04,\n",
       "       1.38086587e-02, 1.08151646e-02, 6.26571516e-03, 9.30682483e-04,\n",
       "       0.00000000e+00, 3.47076966e-03, 7.73419522e-04, 1.07327155e-03,\n",
       "       1.19106702e-03, 0.00000000e+00, 2.81807954e-08, 3.46850000e-05])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 01:02:16,077  <ipython-input-104-ac8315c57481> : INFO  83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Distance',\n",
       " 'Day_of_received',\n",
       " 'Base_consume',\n",
       " 'Discount',\n",
       " 'Discount_money',\n",
       " 'Coupon_category',\n",
       " 'Previous_duration',\n",
       " 'Next_duration',\n",
       " 'o3',\n",
       " 'o4',\n",
       " 'o5',\n",
       " 'o6',\n",
       " 'o8',\n",
       " 'o9',\n",
       " 'o10',\n",
       " 'o14',\n",
       " 'o11',\n",
       " 'o13',\n",
       " 'o15',\n",
       " 'o18',\n",
       " 'o19',\n",
       " 'o20',\n",
       " 'o21',\n",
       " 'o22',\n",
       " 'o17',\n",
       " 'o24',\n",
       " 'o25',\n",
       " 'o26',\n",
       " 'o27',\n",
       " 'o28',\n",
       " 'o29',\n",
       " 'o30',\n",
       " 'o39',\n",
       " 'o32',\n",
       " 'o33',\n",
       " 'o34',\n",
       " 'o35',\n",
       " 'o36',\n",
       " 'u2',\n",
       " 'u3',\n",
       " 'u6',\n",
       " 'u7',\n",
       " 'u8',\n",
       " 'u9',\n",
       " 'u10',\n",
       " 'u12',\n",
       " 'u13',\n",
       " 'u14',\n",
       " 'u16',\n",
       " 'u21',\n",
       " 'u24',\n",
       " 'ucc2',\n",
       " 'ucc6',\n",
       " 'ucc7',\n",
       " 'ucc8',\n",
       " 'ucc9',\n",
       " 'ucc11',\n",
       " 'uc1',\n",
       " 'uc5',\n",
       " 'uc7',\n",
       " 'uc10',\n",
       " 'uc11',\n",
       " 'uc12',\n",
       " 'ud5',\n",
       " 'ud6',\n",
       " 'ud9',\n",
       " 'ud10',\n",
       " 'ud11',\n",
       " 'ud12',\n",
       " 'm2',\n",
       " 'm3',\n",
       " 'm4',\n",
       " 'm5',\n",
       " 'm6',\n",
       " 'm7',\n",
       " 'm8',\n",
       " 'm9',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c4',\n",
       " 'c6',\n",
       " 'c7']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector = []\n",
    "for index, value in enumerate(clf.feature_importances_):\n",
    "    if value > 0:\n",
    "        feature_selector.append(continous[index])\n",
    "\n",
    "logger.info(len(feature_selector))\n",
    "feature_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../features/' + FILENAME + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
