{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler, Normalizer\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby2df(t, name):\n",
    "    t = t.to_frame()\n",
    "    t.columns = [name]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_df = pd.read_csv('../source/ccf_offline_stage1_train.csv', parse_dates = ['Date_received', 'Date'])\n",
    "online_df = pd.read_csv('../source/ccf_online_stage1_train.csv', parse_dates = ['Date_received', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('../source/ccf_offline_stage1_test_revised.csv', parse_dates = ['Date_received'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_range = [datetime.datetime(2016, 5, 16), datetime.datetime(2016, 6, 15)]\n",
    "\n",
    "# time_range_date_received = [datetime.datetime(2016, 2, 1), datetime.datetime(2016, 4, 30)]\n",
    "# time_range_date = [datetime.datetime(2016, 2, 1), datetime.datetime(2016, 5, 15)]\n",
    "\n",
    "# FILENAME = 'dataset_beta'\n",
    "\n",
    "# IS_PRED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = [datetime.datetime(2016, 4, 16), datetime.datetime(2016, 5, 15)]\n",
    "\n",
    "time_range_date_received = [datetime.datetime(2016, 1, 1), datetime.datetime(2016, 3, 31)]\n",
    "time_range_date = [datetime.datetime(2016, 1, 1), datetime.datetime(2016, 4, 15)]\n",
    "\n",
    "FILENAME = 'dataset_alpha'\n",
    "\n",
    "IS_PRED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(row, time_range_date_received, time_range_date):\n",
    "    if ((row.Date >= time_range_date[0]) & (row.Date <= time_range_date[1])) | ((row.Coupon_id == 0) & (row.Date_received >= time_range_date_received[0]) & (row.Date_received <= time_range_date_received[1])):\n",
    "        return row\n",
    "    \n",
    "def dataset_fetch(time_range):\n",
    "    dataset = offline_df[(offline_df.Date_received >= time_range[0]) & (offline_df.Date_received <= time_range[1])].copy()\n",
    "    return dataset\n",
    "    \n",
    "def dataset_split(time_range_date_received, time_range_date):\n",
    "    feature_offline = offline_df.loc[\n",
    "        ((offline_df.Date >= time_range_date[0]) & (offline_df.Date <= time_range_date[1])) | \n",
    "        ((offline_df.Coupon_id == 0) & (offline_df.Date_received >= time_range_date_received[0]) & (offline_df.Date_received <= time_range_date_received[1]))]\n",
    "    feature_online = online_df.loc[\n",
    "        ((online_df.Date >= time_range_date[0]) & (online_df.Date <= time_range_date[1])) | \n",
    "        ((online_df.Coupon_id == 0) & (online_df.Date_received >= time_range_date_received[0]) & (online_df.Date_received <= time_range_date_received[1]))]\n",
    "    \n",
    "    return feature_offline, feature_online\n",
    "\n",
    "if IS_PRED:\n",
    "    dataset = pred_df\n",
    "else:\n",
    "    dataset = dataset_fetch(time_range)\n",
    "\n",
    "feature_alpha_offline, feature_alpha_online = dataset_split(time_range_date_received, time_range_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础数据特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_cat = offline_df['Discount_rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_coupon_feature(row):\n",
    "    if isinstance(row.Discount_rate, str) and row.Discount_rate == 'fixed':\n",
    "        row.Coupon_type = 2\n",
    "        return row\n",
    "    \n",
    "    if isinstance(row.Discount_rate, float):\n",
    "        row.Discount = row.Discount_rate\n",
    "        i, = np.where(discount_cat == row.Discount_rate)\n",
    "        if len(i)>0:\n",
    "            row.Coupon_category = i[0]\n",
    "        return row\n",
    "    \n",
    "    arr = row.Discount_rate.split(':')\n",
    "    if len(arr) == 2:\n",
    "        row.Discount =  (float(arr[0]) - float(arr[1])) / float(arr[0])\n",
    "        row.Coupon_type = 1\n",
    "        row.Base_consume = float(arr[0])\n",
    "        row.Discount_money = float(arr[1])\n",
    "    else:\n",
    "        row.Discount = float(row.Discount_rate)\n",
    "        \n",
    "    i, = np.where(discount_cat == row.Discount_rate)\n",
    "    if len(i)>0:\n",
    "        row.Coupon_category = i[0]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_previous_duration(row):\n",
    "    if row['User_id'] == row['Previous_user_id'] and row['Date_received'] is not None and row['Previous_date_received'] is not None:\n",
    "        return (row.Date_received - row.Previous_date_received).days\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def cal_next_duration(row):\n",
    "    if row['User_id'] == row['Next_user_id'] and row['Date_received'] is not None and row['Next_date_received'] is not None:\n",
    "        return (row.Next_date_received - row.Date_received).days\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_info(dataset):\n",
    "    dataset['Distance'] = dataset['Distance'].fillna(-1)\n",
    "    dataset['Distance'] = dataset['Distance'] + 1\n",
    "\n",
    "    dataset['Month_of_received'] = dataset.apply(lambda row: row.Date_received.month, axis=1)\n",
    "    dataset['Day_of_received'] = dataset.apply(lambda row: row.Date_received.day, axis=1)\n",
    "    dataset['Weekday_of_received'] = dataset.apply(lambda row: row.Date_received.weekday() + 1, axis=1)\n",
    "\n",
    "    dataset['Base_consume'] = 0.0\n",
    "    dataset['Discount'] = 0.0\n",
    "    dataset['Discount_money'] = 0.0\n",
    "    dataset['Coupon_type'] = 0\n",
    "    dataset['Coupon_category'] = 0\n",
    "\n",
    "    dataset = dataset.apply(lambda row: cal_coupon_feature(row), axis=1)\n",
    "\n",
    "    dataset = dataset.sort_values(by=['User_id', 'Date_received'], ascending=True)\n",
    "\n",
    "    dataset['Previous_user_id'] = dataset['User_id'].shift(1)\n",
    "    dataset['Previous_date_received'] = dataset['Date_received'].shift(1)\n",
    "\n",
    "    dataset['Next_user_id'] = dataset['User_id'].shift(-1)\n",
    "    dataset['Next_date_received'] = dataset['Date_received'].shift(-1)\n",
    "\n",
    "    dataset['Previous_duration'] = dataset.apply(lambda row: cal_previous_duration(row), axis=1)\n",
    "    dataset['Next_duration'] = dataset.apply(lambda row: cal_next_duration(row), axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = extract_basic_info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month_of_received</th>\n",
       "      <th>Day_of_received</th>\n",
       "      <th>Weekday_of_received</th>\n",
       "      <th>...</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Discount_money</th>\n",
       "      <th>Coupon_type</th>\n",
       "      <th>Coupon_category</th>\n",
       "      <th>Previous_user_id</th>\n",
       "      <th>Previous_date_received</th>\n",
       "      <th>Next_user_id</th>\n",
       "      <th>Next_date_received</th>\n",
       "      <th>Previous_duration</th>\n",
       "      <th>Next_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1264170</th>\n",
       "      <td>285</td>\n",
       "      <td>450</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>316.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679006</th>\n",
       "      <td>316</td>\n",
       "      <td>7974</td>\n",
       "      <td>8952.0</td>\n",
       "      <td>50:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95577</th>\n",
       "      <td>377</td>\n",
       "      <td>4906</td>\n",
       "      <td>2857.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>316.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>387.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265626</th>\n",
       "      <td>387</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>430.0</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679360</th>\n",
       "      <td>430</td>\n",
       "      <td>7555</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>387.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>467.0</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id Discount_rate  Distance  \\\n",
       "1264170      285          450     1532.0          30:5       3.0   \n",
       "679006       316         7974     8952.0         50:10       1.0   \n",
       "95577        377         4906     2857.0          30:5       0.0   \n",
       "1265626      387         3381     7610.0        200:20       1.0   \n",
       "679360       430         7555     9871.0          30:5       0.0   \n",
       "\n",
       "        Date_received Date  Month_of_received  Day_of_received  \\\n",
       "1264170    2016-05-01  NaT                  5                1   \n",
       "679006     2016-04-30  NaT                  4               30   \n",
       "95577      2016-05-12  NaT                  5               12   \n",
       "1265626    2016-04-21  NaT                  4               21   \n",
       "679360     2016-04-19  NaT                  4               19   \n",
       "\n",
       "         Weekday_of_received      ...        Discount  Discount_money  \\\n",
       "1264170                    7      ...        0.833333             5.0   \n",
       "679006                     6      ...        0.800000            10.0   \n",
       "95577                      4      ...        0.833333             5.0   \n",
       "1265626                    4      ...        0.900000            20.0   \n",
       "679360                     2      ...        0.833333             5.0   \n",
       "\n",
       "         Coupon_type  Coupon_category  Previous_user_id  \\\n",
       "1264170            1                4               NaN   \n",
       "679006             1                5             285.0   \n",
       "95577              1                4             316.0   \n",
       "1265626            1                3             377.0   \n",
       "679360             1                4             387.0   \n",
       "\n",
       "         Previous_date_received Next_user_id  Next_date_received  \\\n",
       "1264170                     NaT        316.0          2016-04-30   \n",
       "679006               2016-05-01        377.0          2016-05-12   \n",
       "95577                2016-04-30        387.0          2016-04-21   \n",
       "1265626              2016-05-12        430.0          2016-04-19   \n",
       "679360               2016-04-21        467.0          2016-04-17   \n",
       "\n",
       "        Previous_duration  Next_duration  \n",
       "1264170                 0              0  \n",
       "679006                  0              0  \n",
       "95577                   0              0  \n",
       "1265626                 0              0  \n",
       "679360                  0              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测区间特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o1**: 用户在预测区获取的优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o1'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o2**: 用户平均15天领取的优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o2'] = d['o1'] / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o3**: 用户平均每天领取多少张优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = d[['User_id', 'o1']].drop_duplicates()\n",
    "\n",
    "t = d.groupby('User_id')['Date_received'].max()\n",
    "u = pd.merge(u, groupby2df(t, 'r_max'), on=['User_id'], how='left')\n",
    "\n",
    "t = d.groupby('User_id')['Date_received'].min()\n",
    "u = pd.merge(u, groupby2df(t, 'r_min'), on=['User_id'], how='left')\n",
    "\n",
    "u['r_day_duration'] = u.apply(lambda row: (row['r_max'] - row['r_min']).days, axis=1)\n",
    "u['o3'] = u['o1'] / u['r_day_duration']\n",
    "d = pd.merge(d, u[['User_id', 'o3']], on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o4**:预测区用户每种类型优惠券领取的数量\n",
    "+ **特征o5**:预测区用户每种类型优惠券领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_category']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o4'), on=['User_id', 'Coupon_category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o5'] = d['o4'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o6**:预测区用户领取优惠券Coupon_id领取的数量\n",
    "+ **特征o8**:预测区用户领取优惠券Coupon_id领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o6'), on=['User_id', 'Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o8'] = d['o6'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o7**:预测区用户领取优惠券Coupon_id在领取日领取的数量\n",
    "+ **特征o9**:预测区用户领取优惠券Coupon_id在领取日领取的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Coupon_id', 'Date_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o7'), on=['User_id', 'Coupon_id', 'Date_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o9'] = d['o7'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o10**:预测区用户领取多少种不同的优惠券\n",
    "+ **特征o14**:预测区用户平均每个领取的优惠券领取了多少张\n",
    "+ **特征o12**:预测区用户领取的不同的优惠券占所有优惠券的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['User_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o10'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o12'] = d['o10'] / d['Coupon_id'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o14'] = d['o1'] / d['o10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o11**:预测区每种优惠券被领取的张数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o11'), on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o13**:预测区用户领取的不同的商户数\n",
    "+ **特征o16**:预测区用户领取的不同的商户数占所有商户数的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['User_id', 'Merchant_id']].drop_duplicates()\n",
    "t = t.groupby(['User_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o13'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o16'] = d['o13'] / d['Merchant_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o15**:预测区用户在每个消费的商户领取的优惠券数\n",
    "+ **特征o18**:预测区用户在每个消费的商户领取的优惠券数在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o15'), on=['User_id', 'Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o18'] = d['o15'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o19**:预测区用户在每个距离上领取的优惠券数量\n",
    "+ **特征o20**:预测区用户在每个距离上领取的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Distance']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o19'), on=['User_id', 'Distance'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o20'] = d['o19'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o21 - o23** 用户领取的优惠券距离最大、最小、平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].max()\n",
    "d = pd.merge(d, groupby2df(t, 'o21'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].min()\n",
    "d = pd.merge(d, groupby2df(t, 'o22'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id'])['Distance'].mean()\n",
    "d = pd.merge(d, groupby2df(t, 'o23'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o17**:预测区用户领取的不同的优惠券分类的优惠券数量\n",
    "+ **特征o24**:预测区用户领取的不同的优惠券分类的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dataset.groupby(['User_id', 'Coupon_type']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o17'), on=['User_id', 'Coupon_type'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o24'] = d['o17'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o25**:预测区用户在领取日领取的优惠券数量\n",
    "+ **特征o26**:预测区用户在领取日领取的优惠券数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Date_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o25'), on=['User_id', 'Date_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o26'] = d['o25'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o27 - o29**用户优惠券折扣的最大、最小、平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].mean()\n",
    "d = pd.merge(d, groupby2df(t, 'o27'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].max()\n",
    "d = pd.merge(d, groupby2df(t, 'o28'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id'])['Discount'].min()\n",
    "d = pd.merge(d, groupby2df(t, 'o29'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o30**:预测区每个商户被领用的优惠券数量\n",
    "+ **特征o38**:预测区每个商户平均被每个用户领取的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o30'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o38'] = d['o30'] / d['User_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o31**:预测区用户在每周不同的weekday领取优惠券的数量\n",
    "+ **特征o39**:预测区用户在每周不同的weekday领取优惠券的数量在所有领取的优惠券中的比率\n",
    "+ **特征o40**:预测区用户在每周不同的month领取优惠券的数量\n",
    "+ **特征o41**:预测区用户在每周不同的month领取优惠券的数量在所有领取的优惠券中的比率\n",
    "+ **特征o42**:预测区用户在每周不同的day领取优惠券的数量\n",
    "+ **特征o43**:预测区用户在每周不同的day领取优惠券的数量在所有领取的优惠券中的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Weekday_of_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o31'), on=['User_id', 'Weekday_of_received'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o39'] = d['o31'] / d['o1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Month_of_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o40'), on=['User_id', 'Month_of_received'], how='left')\n",
    "\n",
    "d['o41'] = d['o40'] / d['o1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d.groupby(['User_id', 'Day_of_received']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o42'), on=['User_id', 'Day_of_received'], how='left')\n",
    "\n",
    "d['o43'] = d['o42'] / d['o1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o32**:预测区商户被多少不同用户领取\n",
    "+ **特征o33**:预测区商户被不同用户平均领取优惠券数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Merchant_id', 'User_id']].drop_duplicates()\n",
    "t = t.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o32'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o33'] = d['o30'] / d['o32']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o34**:每家商户有多少张不同的优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Merchant_id', 'Coupon_id']].drop_duplicates()\n",
    "t = t.groupby(['Merchant_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o34'), on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o35**:每张优惠券被多少不同的人领取了\n",
    "+ **特征o36**:每张优惠券平均被每个领用的用户领取了多少张\n",
    "+ **特征o37**:每张优惠券平均被每个用户领取了多少张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[['Coupon_id', 'User_id']].drop_duplicates()\n",
    "t = t.groupby(['Coupon_id']).size()\n",
    "d = pd.merge(d, groupby2df(t, 'o35'), on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o36'] = d['o11'] / d['o35']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['o37'] = d['o11'] / d['User_id'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征o44**:预测区用户next duration小于16天的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = d[d['Next_duration']<16]\n",
    "t = t.groupby(['User_id'])['Next_duration'].size()\n",
    "d = pd.merge(d, groupby2df(t, 'o44'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_PRED:\n",
    "    dataset['Duration'] = dataset.apply(lambda row: (row['Date'] - row['Date_received']).days, axis=1)\n",
    "    dataset['Label'] = dataset.apply(lambda row: 1 if row['Duration'] < 16 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month_of_received</th>\n",
       "      <th>Day_of_received</th>\n",
       "      <th>Weekday_of_received</th>\n",
       "      <th>...</th>\n",
       "      <th>o42</th>\n",
       "      <th>o43</th>\n",
       "      <th>o32</th>\n",
       "      <th>o33</th>\n",
       "      <th>o34</th>\n",
       "      <th>o35</th>\n",
       "      <th>o36</th>\n",
       "      <th>o37</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285</td>\n",
       "      <td>450</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9926</td>\n",
       "      <td>1.037981</td>\n",
       "      <td>5</td>\n",
       "      <td>1871</td>\n",
       "      <td>1.000534</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>7974</td>\n",
       "      <td>8952.0</td>\n",
       "      <td>50:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>4906</td>\n",
       "      <td>2857.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>387</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19613</td>\n",
       "      <td>1.000510</td>\n",
       "      <td>1</td>\n",
       "      <td>19613</td>\n",
       "      <td>1.000510</td>\n",
       "      <td>0.190683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>7555</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4235</td>\n",
       "      <td>1.006612</td>\n",
       "      <td>3</td>\n",
       "      <td>4132</td>\n",
       "      <td>1.000242</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>467</td>\n",
       "      <td>7555</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4235</td>\n",
       "      <td>1.006612</td>\n",
       "      <td>3</td>\n",
       "      <td>4132</td>\n",
       "      <td>1.000242</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>470</td>\n",
       "      <td>7717</td>\n",
       "      <td>9614.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2648</td>\n",
       "      <td>1.069486</td>\n",
       "      <td>3</td>\n",
       "      <td>2288</td>\n",
       "      <td>1.000437</td>\n",
       "      <td>0.022243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>472</td>\n",
       "      <td>2436</td>\n",
       "      <td>3992.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4859</td>\n",
       "      <td>1.022433</td>\n",
       "      <td>4</td>\n",
       "      <td>4487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>489</td>\n",
       "      <td>6568</td>\n",
       "      <td>4723.0</td>\n",
       "      <td>30:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>53</td>\n",
       "      <td>1.075472</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>489</td>\n",
       "      <td>4057</td>\n",
       "      <td>5112.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_id  Merchant_id  Coupon_id Discount_rate  Distance Date_received Date  \\\n",
       "0      285          450     1532.0          30:5       3.0    2016-05-01  NaT   \n",
       "1      316         7974     8952.0         50:10       1.0    2016-04-30  NaT   \n",
       "2      377         4906     2857.0          30:5       0.0    2016-05-12  NaT   \n",
       "3      387         3381     7610.0        200:20       1.0    2016-04-21  NaT   \n",
       "4      430         7555     9871.0          30:5       0.0    2016-04-19  NaT   \n",
       "5      467         7555     9871.0          30:5       5.0    2016-04-17  NaT   \n",
       "6      470         7717     9614.0          20:1       3.0    2016-04-24  NaT   \n",
       "7      472         2436     3992.0          30:5       0.0    2016-05-04  NaT   \n",
       "8      489         6568     4723.0          30:1       0.0    2016-04-25  NaT   \n",
       "9      489         4057     5112.0          20:1       3.0    2016-04-29  NaT   \n",
       "\n",
       "   Month_of_received  Day_of_received  Weekday_of_received  ...    o42  o43  \\\n",
       "0                  5                1                    7  ...      1  1.0   \n",
       "1                  4               30                    6  ...      1  1.0   \n",
       "2                  5               12                    4  ...      1  1.0   \n",
       "3                  4               21                    4  ...      1  1.0   \n",
       "4                  4               19                    2  ...      1  1.0   \n",
       "5                  4               17                    7  ...      1  1.0   \n",
       "6                  4               24                    7  ...      1  1.0   \n",
       "7                  5                4                    3  ...      1  1.0   \n",
       "8                  4               25                    1  ...      1  0.5   \n",
       "9                  4               29                    5  ...      1  0.5   \n",
       "\n",
       "     o32       o33  o34    o35       o36       o37 Duration  Label  \n",
       "0   9926  1.037981    5   1871  1.000534  0.018191      NaN      0  \n",
       "1    360  1.000000    1    360  1.000000  0.003498      NaN      0  \n",
       "2     28  1.000000    3     11  1.000000  0.000107      NaN      0  \n",
       "3  19613  1.000510    1  19613  1.000510  0.190683      NaN      0  \n",
       "4   4235  1.006612    3   4132  1.000242  0.040162      NaN      0  \n",
       "5   4235  1.006612    3   4132  1.000242  0.040162      NaN      0  \n",
       "6   2648  1.069486    3   2288  1.000437  0.022243      NaN      0  \n",
       "7   4859  1.022433    4   4487  1.000000  0.043602      NaN      0  \n",
       "8     53  1.075472    3     38  1.052632  0.000389      NaN      0  \n",
       "9     12  1.000000    2      6  1.000000  0.000058      NaN      0  \n",
       "\n",
       "[10 rows x 66 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(df, keys, suffix):\n",
    "    t = receive.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'1'), on=keys, how='left')\n",
    "\n",
    "    t = consume.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'2'), on=keys, how='left')\n",
    "\n",
    "    t = use.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, suffix+'3'), on=keys, how='left')\n",
    "\n",
    "    df[suffix+'4'] = df[suffix+'1'] - df[suffix+'3']\n",
    "    df[suffix+'5'] = df[suffix+'1'] - df[suffix+'2']\n",
    "    \n",
    "    df[suffix+'6'] = df[suffix+'3'] / df[suffix+'4']\n",
    "    df[suffix+'7'] = df[suffix+'2'] / df[suffix+'5']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mean_max_min(d, df, keys, column_name, prefix, count):\n",
    "    t = d.groupby(keys)[column_name].mean()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "\n",
    "    count = count + 1\n",
    "    t = d.groupby(keys)[column_name].max()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "\n",
    "    count = count + 1\n",
    "    t = d.groupby(keys)[column_name].min()\n",
    "    df = pd.merge(df, groupby2df(t, prefix+str(count)), on=keys, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_size(d, df, groups, keys, column_name):\n",
    "    t = d[groups].drop_duplicates()\n",
    "    t = t.groupby(keys).size()\n",
    "    df = pd.merge(df, groupby2df(t, column_name), on=keys, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拆分特征数据集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "feature_alpha_offline = extract_basic_info(feature_alpha_offline)\n",
    "\n",
    "feature_alpha_offline['Duration'] = feature_alpha_offline.apply(lambda row: (row['Date'] - row['Date_received']).days, axis=1)\n",
    "feature_alpha_offline['Label'] = feature_alpha_offline.apply(lambda row: 1 if row['Duration'] < 16 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "receive = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0]\n",
    "consume = receive[receive['Duration'] >= 0]\n",
    "use = receive[receive['Label']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u1**:用户领取优惠券的数量\n",
    "+ **特征u2**:用户消费优惠券的数量\n",
    "+ **特征u3**:用户15天内消费优惠券的数量\n",
    "+ **特征u4**:用户15天内没有消费优惠券的数量\n",
    "+ **特征u5**:用户用户没有消费优惠券的数量\n",
    "+ **特征u6**:用户15天内消费优惠券的数量 比 用户15天内没有消费优惠券的数量\n",
    "+ **特征u7**:用户消费优惠券的数量 比 用户用户没有消费优惠券的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = get_count(u, ['User_id'], 'u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u8**:用户消费优惠券消费天数的平均值\n",
    "+ **特征u9**:用户消费优惠券消费天数的最大值\n",
    "+ **特征u10**:用户消费优惠券消费天数的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(consume, u, ['User_id'], 'Duration', 'u', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u11**:用户消费优惠券折扣率的平均值\n",
    "+ **特征u12**:用户消费优惠券折扣率的最大值\n",
    "+ **特征u13**:用户消费优惠券折扣率的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(consume, u, ['User_id'], 'Discount', 'u', 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u14**:用户消费多少种不同优惠券\n",
    "+ **特征u15**:用户15天内消费多少种不同优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = get_unique_size(consume, u, ['User_id', 'Coupon_id'], ['User_id'], 'u14')\n",
    "u = get_unique_size(use, u, ['User_id', 'Coupon_id'], ['User_id'], 'u15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u16**:用户消费多少个不同商家的优惠券\n",
    "+ **特征u17**:用户15天内消费多少个不同商家的优惠券"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = get_unique_size(consume, u, ['User_id', 'Merchant_id'], ['User_id'], 'u16')\n",
    "u = get_unique_size(use, u, ['User_id', 'Merchant_id'], ['User_id'], 'u17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征u18**:用户15天内消费优惠券的核销率\n",
    "+ **特征u19**:用户消费优惠券的核销率\n",
    "+ **特征u20**:用户15天内平均消费领取天数在15天内的优惠券的数量\n",
    "+ **特征u21**:用户15天内平均消费优惠券的数量\n",
    "+ **特征u22**:用户15天内平均领取优惠券的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "u['u18'] = u['u3'] / u['u1']\n",
    "u['u19'] = u['u2'] / u['u1']\n",
    "\n",
    "u['u20'] = u['u3'] / 15\n",
    "u['u21'] = u['u2'] / 15\n",
    "u['u22'] = u['u1'] / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = process_mean_max_min(use, u, ['User_id'], 'Duration', 'u', 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, u, on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户-优惠券分类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Coupon_category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = get_count(ucc, ['User_id', 'Coupon_category'], 'ucc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucc = process_mean_max_min(consume, ucc, ['User_id', 'Coupon_category'], 'Duration', 'ucc', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ucc, on=['User_id', 'Coupon_category'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ucc11'] = dataset['ucc3'] / dataset['u1']\n",
    "dataset['ucc12'] = dataset['ucc2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户 - 优惠券特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Coupon_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征uc1**:不同coupon_id,用户领取优惠券的数量\n",
    "+ **特征uc2**:不同coupon_id,用户消费优惠券的数量\n",
    "+ **特征uc3**:不同coupon_id,用户15天内消费优惠券的数量\n",
    "+ **特征uc4**:不同coupon_id,用户15天内没有消费优惠券的数量\n",
    "+ **特征uc5**:不同coupon_id,用户用户没有消费优惠券的数量\n",
    "+ **特征uc6**:不同coupon_id,用户15天内消费优惠券的数量 比 用户15天内没有消费优惠券的数量\n",
    "+ **特征uc7**:不同coupon_id,用户消费优惠券的数量 比 用户用户没有消费优惠券的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = get_count(uc, ['User_id', 'Coupon_id'], 'uc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征uc8**:不同coupon_id,用户消费优惠券消费天数的平均值\n",
    "+ **特征uc9**:不同coupon_id,用户消费优惠券消费天数的最大值\n",
    "+ **特征uc10**:不同coupon_id,用户消费优惠券消费天数的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = process_mean_max_min(consume, uc, ['User_id', 'Coupon_id'], 'Duration', 'uc', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, uc, on=['User_id', 'Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征uc11**:不同coupon_id,用户15天内消费优惠券的核销率\n",
    "+ **特征uc12**:不同coupon_id,用户消费优惠券的核销率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['uc11'] = dataset['uc3'] / dataset['u1']\n",
    "dataset['uc12'] = dataset['uc2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户 - 距离特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Distance']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = get_count(ud, ['User_id', 'Distance'], 'ud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = process_mean_max_min(consume, ud, ['User_id', 'Distance'], 'Duration', 'ud', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ud, on=['User_id', 'Distance'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ud11'] = dataset['ud3'] / dataset['u1']\n",
    "dataset['ud12'] = dataset['ud2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户 - 商户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['User_id', 'Merchant_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征um1**:不同merchant_id,用户领取优惠券的数量\n",
    "+ **特征um2**:不同merchant_id,用户消费优惠券的数量\n",
    "+ **特征um3**:不同merchant_id,用户15天内消费优惠券的数量\n",
    "+ **特征um4**:不同merchant_id,用户15天内没有消费优惠券的数量\n",
    "+ **特征um5**:不同merchant_id,用户用户没有消费优惠券的数量\n",
    "+ **特征um6**:不同merchant_id,用户15天内消费优惠券的数量 比 用户15天内没有消费优惠券的数量\n",
    "+ **特征um7**:不同merchant_id,用户消费优惠券的数量 比 用户用户没有消费优惠券的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = get_count(um, ['User_id', 'Merchant_id'], 'um')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征um8**:不同merchant_id,用户消费优惠券消费天数的平均值\n",
    "+ **特征um9**:不同merchant_id,用户消费优惠券消费天数的最大值\n",
    "+ **特征um10**:不同merchant_id,用户消费优惠券消费天数的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = process_mean_max_min(consume, um, ['User_id', 'Merchant_id'], 'Duration', 'um', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, um, on=['User_id', 'Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征um11**:不同merchant_id,用户15天内消费优惠券的核销率\n",
    "+ **特征um12**:不同merchant_id,用户消费优惠券的核销率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['um11'] = dataset['um3'] / dataset['u1']\n",
    "dataset['um12'] = dataset['um2'] / dataset['u1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **特征um13**:不同merchant_id,用户15天内消费优惠券在15天内平均核销数\n",
    "+ **特征um14**:不同merchant_id,用户消费优惠券在15天内平均核销数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['um13'] = dataset['um3'] / 15\n",
    "dataset['um14'] = dataset['um2'] / 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 商户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Merchant_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_count(m, ['Merchant_id'], 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = process_mean_max_min(consume, m, ['Merchant_id'], 'Duration', 'm', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_unique_size(consume, m, ['Merchant_id', 'User_id'], ['Merchant_id'], 'm11')\n",
    "m = get_unique_size(use, m, ['Merchant_id', 'User_id'], ['Merchant_id'], 'm12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "m['m13'] = m['m2'] / m['m11']\n",
    "m['m14'] = m['m3'] / m['m12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, m, on=['Merchant_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优惠券特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Coupon_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_count(c, ['Coupon_id'], 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = process_mean_max_min(consume, c, ['Coupon_id'], 'Duration', 'c', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_unique_size(consume, c, ['Coupon_id', 'User_id'], ['Coupon_id'], 'c11')\n",
    "c = get_unique_size(use, c, ['Coupon_id', 'User_id'], ['Coupon_id'], 'c12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['c13'] = c['c2'] / c['c11']\n",
    "c['c14'] = c['c3'] / c['c12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, c, on=['Coupon_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Coupon_id', 'Date_received']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = get_count(cd, ['Coupon_id', 'Date_received'], 'cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, cd, on=['Coupon_id', 'Date_received'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优惠券分类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = feature_alpha_offline[feature_alpha_offline['Coupon_id']>0][['Discount_rate']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = get_count(dr, ['Discount_rate'], 'dr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, dr, on=['Discount_rate'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线上用户特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ou = feature_alpha_online[['User_id']].drop_duplicates()\n",
    "\n",
    "t = feature_alpha_online.groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou1'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 0].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou2'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 1].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou3'), on=['User_id'], how='left')\n",
    "\n",
    "t = feature_alpha_online[feature_alpha_online.Action == 2].groupby(['User_id']).size()\n",
    "ou = pd.merge(ou, groupby2df(t, 'ou4'), on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset, ou, on=['User_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造特征选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Distance',\n",
       "       'Date_received', 'Date', 'Month_of_received', 'Day_of_received',\n",
       "       'Weekday_of_received', 'Base_consume', 'Discount',\n",
       "       'Discount_money', 'Coupon_type', 'Coupon_category',\n",
       "       'Previous_user_id', 'Previous_date_received', 'Next_user_id',\n",
       "       'Next_date_received', 'Previous_duration', 'Next_duration', 'o1',\n",
       "       'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
       "       'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
       "       'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
       "       'o30', 'o38', 'o31', 'o39', 'o40', 'o41', 'o42', 'o43', 'o32',\n",
       "       'o33', 'o34', 'o35', 'o36', 'o37', 'Duration', 'Label', 'u1', 'u2',\n",
       "       'u3', 'u4', 'u5', 'u6', 'u7', 'u8', 'u9', 'u10', 'u11', 'u12',\n",
       "       'u13', 'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u21',\n",
       "       'u22', 'u23', 'u24', 'u25', 'ucc1', 'ucc2', 'ucc3', 'ucc4', 'ucc5',\n",
       "       'ucc6', 'ucc7', 'ucc8', 'ucc9', 'ucc10', 'ucc11', 'ucc12', 'uc1',\n",
       "       'uc2', 'uc3', 'uc4', 'uc5', 'uc6', 'uc7', 'uc8', 'uc9', 'uc10',\n",
       "       'uc11', 'uc12', 'ud1', 'ud2', 'ud3', 'ud4', 'ud5', 'ud6', 'ud7',\n",
       "       'ud8', 'ud9', 'ud10', 'ud11', 'ud12', 'um1', 'um2', 'um3', 'um4',\n",
       "       'um5', 'um6', 'um7', 'um8', 'um9', 'um10', 'um11', 'um12', 'um13',\n",
       "       'um14', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9',\n",
       "       'm10', 'm11', 'm12', 'm13', 'm14', 'c1', 'c2', 'c3', 'c4', 'c5',\n",
       "       'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'cd1',\n",
       "       'cd2', 'cd3', 'cd4', 'cd5', 'cd6', 'cd7', 'dr1', 'dr2', 'dr3',\n",
       "       'dr4', 'dr5', 'dr6', 'dr7', 'ou1', 'ou2', 'ou3', 'ou4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [\n",
    "    'Distance',\n",
    "    'Base_consume', 'Discount',\n",
    "    'Discount_money', \n",
    "    'Previous_duration', 'Next_duration', 'o1',\n",
    "    'o2', 'o3', 'o4', 'o5', 'o6', 'o8', 'o7', 'o9', 'o10', 'o12',\n",
    "    'o14', 'o11', 'o13', 'o16', 'o15', 'o18', 'o19', 'o20', 'o21',\n",
    "    'o22', 'o23', 'o17', 'o24', 'o25', 'o26', 'o27', 'o28', 'o29',\n",
    "    'o30', 'o38', 'o31', 'o39', 'o32', 'o33', 'o34', 'o35', 'o36','o37', 'o40', 'o41', 'o42', 'o43','o44',\n",
    "    'u1', 'u2', 'u3', 'u4', 'u5', 'u6',\n",
    "    'u7', 'u8', 'u9', 'u10', 'u11', 'u12', 'u13', 'u14', 'u15', 'u16',\n",
    "    'u17', 'u18', 'u19', 'u20', 'u21', 'u22', 'u23', 'u24', 'u25',\n",
    "    'ucc1', 'ucc2', 'ucc3', 'ucc4', 'ucc5', 'ucc6', 'ucc7', 'ucc8',\n",
    "    'ucc9', 'ucc10', 'ucc11', 'ucc12', 'uc1', 'uc2', 'uc3', 'uc4',\n",
    "    'uc5', 'uc6', 'uc7', 'uc8', 'uc9', 'uc10', 'uc11', 'uc12', 'ud1',\n",
    "    'ud2', 'ud3', 'ud4', 'ud5', 'ud6', 'ud7', 'ud8', 'ud9', 'ud10',\n",
    "    'ud11', 'ud12', 'um1', 'um2', 'um3', 'um4', 'um5', 'um6', 'um7',\n",
    "    'um8', 'um9', 'um10', 'um11', 'um12', 'um13', 'um14', 'm1', 'm2',\n",
    "    'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11', 'm12',\n",
    "    'm13', 'm14', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9',\n",
    "    'c10', 'c11', 'c12', 'c13', 'c14', 'cd1', 'cd2', 'cd3', 'cd4',\n",
    "    'cd5', 'cd6', 'cd7', 'dr1', 'dr2', 'dr3', 'dr4', 'dr5', 'dr6',\n",
    "    'dr7', 'ou1', 'ou2', 'ou3', 'ou4']\n",
    "\n",
    "label = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processor = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "#             ('scale', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "            ('normalize', Normalizer())\n",
    "        ])),\n",
    "    ])),\n",
    "#     ('sc4gbdt', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n",
      "/Users/leewind/.local/share/virtualenvs/leewind-p6XO93Th/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processor.fit(dataset, dataset['Label'].values.ravel())\n",
    "clf = GradientBoostingClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "clf.fit(feature_processor.transform(dataset), dataset['Label'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33192260e-03, 4.97006059e-02, 0.00000000e+00, 6.38757399e-03,\n",
       "       1.55144286e-03, 1.71183875e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.58561036e-03, 1.16848177e-02, 1.39405200e-03, 5.91746859e-02,\n",
       "       1.64860565e-03, 2.54103807e-04, 1.41835410e-02, 6.88131961e-03,\n",
       "       0.00000000e+00, 4.80479239e-02, 1.46260171e-02, 8.35451202e-03,\n",
       "       0.00000000e+00, 7.29123268e-02, 3.03559375e-03, 1.89617898e-03,\n",
       "       0.00000000e+00, 2.92839046e-03, 9.09964166e-04, 1.03594760e-03,\n",
       "       1.46025713e-03, 1.40402772e-04, 1.43743247e-03, 1.93601220e-02,\n",
       "       6.89934023e-04, 0.00000000e+00, 1.13487940e-02, 8.10629903e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.57067518e-02,\n",
       "       5.52732823e-02, 3.88899367e-03, 2.08524597e-01, 1.75556981e-02,\n",
       "       0.00000000e+00, 2.78645589e-03, 8.97523002e-04, 3.62538671e-03,\n",
       "       2.60227727e-02, 0.00000000e+00, 1.56777467e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.48462346e-03,\n",
       "       0.00000000e+00, 4.13270880e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.27972211e-04, 2.79879552e-08, 2.19477680e-02, 0.00000000e+00,\n",
       "       2.04220570e-04, 2.26530373e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.23184670e-04,\n",
       "       8.17184329e-04, 7.55269222e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.95652234e-04, 0.00000000e+00, 0.00000000e+00, 1.01634165e-03,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.05139916e-07,\n",
       "       2.74160286e-04, 1.05990491e-04, 1.54661815e-04, 2.40686607e-03,\n",
       "       1.29111081e-03, 1.18287976e-03, 8.54406196e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.71761762e-05,\n",
       "       5.22713289e-05, 0.00000000e+00, 3.93133911e-04, 7.84579541e-04,\n",
       "       2.29668037e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.80186652e-03, 2.41667032e-03, 9.14221426e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.17117601e-04, 8.33073217e-04, 2.83197367e-03,\n",
       "       2.64987380e-03, 2.83527190e-03, 1.11768612e-03, 0.00000000e+00,\n",
       "       5.98029208e-03, 3.91615322e-03, 2.73617542e-03, 2.99990618e-04,\n",
       "       1.10890877e-03, 7.35301085e-03, 1.48813263e-03, 1.24797906e-03,\n",
       "       1.01448959e-03, 1.33192060e-03, 3.90210400e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 3.03221280e-03, 1.50363317e-03,\n",
       "       5.03224173e-03, 1.49052497e-03, 4.85215107e-04, 0.00000000e+00,\n",
       "       5.57089227e-04, 1.40775096e-03, 5.12323047e-04, 1.44748101e-02,\n",
       "       3.94787510e-03, 0.00000000e+00, 1.33618951e-03, 3.30224764e-03,\n",
       "       0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 17:13:02,329  <ipython-input-142-ac8315c57481> : INFO  96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Distance',\n",
       " 'Base_consume',\n",
       " 'Discount_money',\n",
       " 'Previous_duration',\n",
       " 'Next_duration',\n",
       " 'o3',\n",
       " 'o4',\n",
       " 'o5',\n",
       " 'o6',\n",
       " 'o8',\n",
       " 'o7',\n",
       " 'o9',\n",
       " 'o10',\n",
       " 'o14',\n",
       " 'o11',\n",
       " 'o13',\n",
       " 'o15',\n",
       " 'o18',\n",
       " 'o19',\n",
       " 'o21',\n",
       " 'o22',\n",
       " 'o23',\n",
       " 'o17',\n",
       " 'o24',\n",
       " 'o25',\n",
       " 'o26',\n",
       " 'o27',\n",
       " 'o29',\n",
       " 'o30',\n",
       " 'o32',\n",
       " 'o33',\n",
       " 'o34',\n",
       " 'o35',\n",
       " 'o36',\n",
       " 'o40',\n",
       " 'o41',\n",
       " 'o42',\n",
       " 'o43',\n",
       " 'u1',\n",
       " 'u6',\n",
       " 'u8',\n",
       " 'u19',\n",
       " 'u20',\n",
       " 'u21',\n",
       " 'u23',\n",
       " 'u24',\n",
       " 'ucc5',\n",
       " 'ucc6',\n",
       " 'ucc7',\n",
       " 'ucc10',\n",
       " 'uc1',\n",
       " 'uc5',\n",
       " 'uc6',\n",
       " 'uc7',\n",
       " 'uc8',\n",
       " 'uc9',\n",
       " 'uc10',\n",
       " 'uc11',\n",
       " 'uc12',\n",
       " 'ud5',\n",
       " 'ud6',\n",
       " 'ud8',\n",
       " 'ud9',\n",
       " 'ud10',\n",
       " 'um2',\n",
       " 'um3',\n",
       " 'um4',\n",
       " 'um7',\n",
       " 'um8',\n",
       " 'um9',\n",
       " 'um10',\n",
       " 'um11',\n",
       " 'um12',\n",
       " 'um14',\n",
       " 'm1',\n",
       " 'm2',\n",
       " 'm3',\n",
       " 'm4',\n",
       " 'm5',\n",
       " 'm6',\n",
       " 'm7',\n",
       " 'm8',\n",
       " 'm9',\n",
       " 'm10',\n",
       " 'm14',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c4',\n",
       " 'c6',\n",
       " 'c7',\n",
       " 'c8',\n",
       " 'c9',\n",
       " 'c10',\n",
       " 'c12',\n",
       " 'c13']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector = []\n",
    "for index, value in enumerate(clf.feature_importances_):\n",
    "    if value > 0:\n",
    "        feature_selector.append(continous[index])\n",
    "\n",
    "logger.info(len(feature_selector))\n",
    "feature_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../features/' + FILENAME + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>132889.000000</td>\n",
       "      <td>132889.000000</td>\n",
       "      <td>132878.000000</td>\n",
       "      <td>132878.000000</td>\n",
       "      <td>132889.0</td>\n",
       "      <td>128485.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4031.576316</td>\n",
       "      <td>4031.576316</td>\n",
       "      <td>3498.627959</td>\n",
       "      <td>533.282018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.590542</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4887.161253</td>\n",
       "      <td>4887.161253</td>\n",
       "      <td>4328.805707</td>\n",
       "      <td>596.598613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.299269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>744.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.678454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1132.000000</td>\n",
       "      <td>1132.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6608.000000</td>\n",
       "      <td>6608.000000</td>\n",
       "      <td>6360.000000</td>\n",
       "      <td>1216.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.114152</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12155.000000</td>\n",
       "      <td>12155.000000</td>\n",
       "      <td>10657.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dr1            dr2            dr3            dr4       dr5  \\\n",
       "count  132889.000000  132889.000000  132878.000000  132878.000000  132889.0   \n",
       "mean     4031.576316    4031.576316    3498.627959     533.282018       0.0   \n",
       "std      4887.161253    4887.161253    4328.805707     596.598613       0.0   \n",
       "min         1.000000       1.000000       1.000000       0.000000       0.0   \n",
       "25%       744.000000     744.000000     620.000000     123.000000       0.0   \n",
       "50%      1132.000000    1132.000000     800.000000     248.000000       0.0   \n",
       "75%      6608.000000    6608.000000    6360.000000    1216.000000       0.0   \n",
       "max     12155.000000   12155.000000   10657.000000    1498.000000       0.0   \n",
       "\n",
       "                 dr6  dr7  \n",
       "count  128485.000000  0.0  \n",
       "mean        6.590542  NaN  \n",
       "std         6.299269  NaN  \n",
       "min         1.000000  NaN  \n",
       "25%         2.678454  NaN  \n",
       "50%         5.000000  NaN  \n",
       "75%         7.114152  NaN  \n",
       "max        31.666667  NaN  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['dr1','dr2','dr3','dr4','dr5','dr6','dr7']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
